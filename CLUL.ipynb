{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf742fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If U are using SageMaker Prepare for the dataset\n",
    "!pip install awscli\n",
    "!aws s3 cp s3://handata/ref_youtube_audio/ ref_youtube_audio/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -U openai-whisper\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e7a758-d85d-444c-aede-9f31a6fe37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, WhisperForAudioClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from categories import ytvos_category_dict\n",
    "import numpy as np\n",
    "from util import read_aws_json,read_aws_wav,read_local_json,read_local_wav\n",
    "import logging\n",
    "from torch import optim\n",
    "from losses import get_loss_func\n",
    "from utils.evaluate import Evaluator\n",
    "from util import infoNCE_loss\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "SageMaker = False\n",
    "Local = True\n",
    "ROOT = 'C:/Users/Administrator/Desktop/CLUL-main/data/'\n",
    "SAVEDIR = 'C:/Users/Administrator/Desktop/CLUL-main/run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a734c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Audio_Encoder(nn.Module):\n",
    "    def __init__(self, feature_extractor, model, num_class=66,dropout_prob=0.2,pool_num = 100,bias = True):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.encoder = model.encoder\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "          param.requires_grad = False\n",
    "        self.projector = nn.Linear(in_features=768, out_features=256, bias=True)\n",
    "        self.classifier = nn.Linear(256, num_class)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(pool_num,1), stride=(pool_num,1))\n",
    "        # self.norm_layer = nn.LayerNorm(256, eps=1e-5, bias=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(2048, affine=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(1500//pool_num * 256, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 256)\n",
    "        self.fc3 = nn.Linear(256, 65)\n",
    "\n",
    "    def forward(self, audios):\n",
    "        input_features = []\n",
    "        for audio in audios:\n",
    "\n",
    "            feature = self.feature_extractor(audio.cpu(),sampling_rate=16000,return_tensors=\"pt\").input_features\n",
    "            input_features.append(feature)\n",
    "\n",
    "        input_features = torch.cat(input_features, dim=0).to(self.device)\n",
    "        hidden_states = self.encoder(input_features)\n",
    "        # hidden_states = self.projector(hidden_states)\n",
    "        # pooled_output = hidden_states.mean(dim=1)\n",
    "        # logits = self.classifier(pooled_output)\n",
    "\n",
    "        x = self.avg_pool(hidden_states)\n",
    "\n",
    "        x = self.projector(x)\n",
    "        # x = self.positionencoding(x)\n",
    "        feature = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(feature)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        output_dict = {\n",
    "            'clipwise_output': x,\n",
    "            'feature': feature,\n",
    "            'embedding': hidden_states}\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "class ytvos_Dataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame, sr=44100, num_class=65):\n",
    "        self.data_frame = data_frame\n",
    "        self.sr = sr\n",
    "        self.num_class = num_class\n",
    "        self.data_root = '/home/user/SED_Adaptation_Classifier-main/data/ref_youtube_audio/audio'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        audio_name = self.data_frame.iloc[index][\"video\"]\n",
    "        audio_id = self.data_frame.iloc[index][\"audio\"]\n",
    "        audio_path = 'ref_youtube_audio/audio' + '/' + audio_name + '/' + audio_id + '.wav'\n",
    "        name = audio_name + self.data_frame.iloc[index][\"exp\"]\n",
    "\n",
    "        \n",
    "        waveform = read_local_wav(ROOT + audio_path)\n",
    "#         waveform = whisper.load_audio(audio_path,sr = 16000)\n",
    "\n",
    "        tag = self.data_frame.iloc[index][\"category\"]\n",
    "        target = ytvos_category_dict[self.data_frame.iloc[index][\"category\"]]\n",
    "        target = np.eye(self.num_class)[target]\n",
    "        data_dict = {'audio_name': name, 'waveform': waveform, 'target': target, 'tag': tag}\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "def get_datalist(cur_iter):\n",
    "        task_id = cur_iter\n",
    "        task_train_metas = []\n",
    "        task_test_metas = []\n",
    "\n",
    "       \n",
    "        metas = read_local_json(ROOT + 'task_split_1/metas.json')['metas']\n",
    "        tasks = read_local_json(ROOT + 'task_split_1/task{}.json'.format(task_id))[str(task_id)]\n",
    "\n",
    "        for category,task_metas_dict in tasks.items():\n",
    "            train_ids = task_metas_dict['train']\n",
    "            test_ids = task_metas_dict['test']\n",
    "            for train_id in train_ids:\n",
    "                task_train_metas.append(metas[train_id])\n",
    "            for test_id in test_ids:\n",
    "                task_test_metas.append(metas[test_id])\n",
    "\n",
    "        return task_train_metas,task_test_metas\n",
    "    \n",
    "def default_collate_fn(batch):\n",
    "    audio_name = [data['audio_name'] for data in batch]\n",
    "    waveform = [torch.from_numpy(data['waveform']) for data in batch]\n",
    "    target = [data['target'] for data in batch]\n",
    "\n",
    "    # waveform = torch.FloatTensor(waveform)\n",
    "    # waveform = pad_sequence(waveform, batch_first=True, padding_value=0)\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    return {'audio_name': audio_name, 'waveform': waveform, 'target': target}\n",
    "\n",
    "def get_dataloader(data_frame, dataset, split, batch_size, num_class, num_workers=8):\n",
    "    assert dataset == \"ref_youtube_audio\"\n",
    "    dataset = ytvos_Dataset(data_frame=data_frame)\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                      shuffle=True, drop_last=False,\n",
    "                      num_workers=num_workers, collate_fn=default_collate_fn)\n",
    "\n",
    "def get_train_test_dataloader(batch_size, n_worker, train_list, test_list):\n",
    "    train_loader = get_dataloader(pd.DataFrame(train_list), 'ref_youtube_audio', split='train', batch_size=batch_size, num_class=66,\n",
    "                                  num_workers=n_worker)\n",
    "    test_loader = get_dataloader(pd.DataFrame(test_list), 'ref_youtube_audio', split='test', batch_size=batch_size, num_class=66,\n",
    "                                 num_workers=n_worker)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d6cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLUL:\n",
    "    def __init__(self,batch_size = 16,lr = 1e-3,memory_size = 500,\n",
    "                 forget_size = 100,epoch=1,loss ='focal_loss',\n",
    "                 total_class_num = 65,mode = 'CLUL _no_foget_bank',\n",
    "                 patience = 10,n_worker = 0,\n",
    "                 **kwargs):\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "        whisper_model = whisper.load_model(\"small\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = Audio_Encoder(feature_extractor, whisper_model).to(self.device)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.logger = logging.getLogger()\n",
    "        self.forget_list = []\n",
    "        self.memory_list = []\n",
    "        self.memory_size = memory_size\n",
    "        self.forget_size = forget_size\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas=(0.9, 0.999))\n",
    "        self.criterion = get_loss_func(loss)\n",
    "        self.num_pretrain_class = 0\n",
    "        self.evaluator = Evaluator(self.model, self.num_pretrain_class, self.device)\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.total_class_num = total_class_num\n",
    "        self.forget_label = total_class_num\n",
    "        self.n_worker = n_worker\n",
    "        self.cltask = {\n",
    "            'task0':[15, 17, 60, 50, 32, 24, 63, 36, 31, 40, 52, 4, 25],\n",
    "            \"task1\":[48, 54, 35, 62, 13, 42, 37, 49, 51, 45, 44, 14, 5],\n",
    "            \"task2\":[46, 18, 57, 28, 11, 30, 61, 27, 22, 2, 29, 0, 19],\n",
    "            \"task3\":[3, 59, 10, 12, 8, 1, 26, 23, 34, 58, 64, 56, 41],\n",
    "            \"task4\":[47, 20, 53, 39, 9, 21, 16, 38, 33, 43, 6, 7, 55]\n",
    "        }\n",
    "        self.ultask = {\n",
    "        \n",
    "            \"un_task1\":[15,17,60],\n",
    "            \"un_task2\": [48, 54, 35],\n",
    "            \"un_task3\":[46, 18, 57],\n",
    "            \"un_task4\" : [3, 59, 10],\n",
    "            \"un_task5\" : [47, 20, 53]\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def evaluate(self,model_path,cur_iter):\n",
    "        self.change_model(model_path)\n",
    "        train_list,test_list = get_datalist(cur_iter)\n",
    "        _, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        test_statistics = self.evaluator.evaluate(test_loader)\n",
    "        print(f\"Task {cur_iter} | Evaluation Accuracy: {test_statistics['precision']}|Evaluation f1_score: {test_statistics['f1_score']}|Evaluation precision {test_statistics['precision']}\")\n",
    "\n",
    "\n",
    "    def train(self,cur_iter):\n",
    "        streamed_list,test_list = get_datalist(cur_iter)\n",
    "        train_list = streamed_list + self.memory_list\n",
    "        random.shuffle(train_list)\n",
    "        train_loader, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "\n",
    "        self.logger.info(f\"Streamed samples: {len(streamed_list)}\")\n",
    "        self.logger.info(f\"In-memory samples: {len(self.memory_list)}\")\n",
    "        self.logger.info(f\"Train samples: {len(train_list)}\")\n",
    "        self.logger.info(f\"Test samples: {len(test_list)}\")\n",
    "        # logger.info(f\"Model: {self.model}\")\n",
    "        self.logger.info(f\"Optimizer: {self.optimizer}\")\n",
    "        acc_list = []\n",
    "        best = {'acc': 0, 'epoch': 0,'f1_score':0}\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            self.logger.info(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            test_statistics = self.evaluator.evaluate(test_loader)\n",
    "            ave_f1_score = np.mean(test_statistics['f1_score'])\n",
    "            ave_acc = np.mean(test_statistics['accuracy'])\n",
    "            acc_list.append(ave_acc)\n",
    "            self.logger.info(f\"Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}\")\n",
    "            self.logger.info(f'Current Accuracy: {ave_acc} in epoch {epoch}.|Current f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "            print(f\"Task {cur_iter} | Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}|Evaluation precision {test_statistics['precision']}\")\n",
    "            \n",
    "\n",
    "            if ave_f1_score > best['f1_score']:\n",
    "                best['acc'] = ave_acc\n",
    "                best['f1_score'] = ave_f1_score\n",
    "                best['epoch'] = epoch\n",
    "                self.logger.info(f'Best Accuracy: {ave_acc} in epoch {epoch}.|Best f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Evaluation Accuracy: {best['acc']}|Evaluation f1_score: {best['f1_score']}\")\n",
    "        return \n",
    "    def change_model(self, path):\n",
    "        checkpoint_dict = torch.load(path)\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in checkpoint_dict:\n",
    "                param.data.copy_(checkpoint_dict[name])\n",
    "                \n",
    "    def equal_class_sampling(self, samples, num_class):\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cur_class_list = []\n",
    "        for i in range(num_class//13):\n",
    "            cur_class_list += class_list[i]\n",
    "        mem_per_cls = self.memory_size // num_class\n",
    "        sample_df = pd.DataFrame(samples)\n",
    "\n",
    "        # Warning: assuming the classes were ordered following task number.\n",
    "        ret = []\n",
    "        for y in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == y]\n",
    "            ret += cls_df.sample(n=min(mem_per_cls, len(cls_df))).to_dict(\n",
    "                orient=\"records\"\n",
    "            )\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            self.logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            self.logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_data(self, infer_loader, augment):\n",
    "        Z, Z_, predict_list = [], [], []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for id, data in enumerate(infer_loader):\n",
    "                wavs = data['waveform']\n",
    "                aug_wavs = []\n",
    "                for wav in wavs:\n",
    "                    aug_wav = augment(wav.unsqueeze(0).unsqueeze(0), sample_rate=1600)\n",
    "                    aug_wavs.append(torch.as_tensor(aug_wav.squeeze(0).squeeze(0), dtype=torch.float32))\n",
    "\n",
    "                output_dict = self.model(data['waveform'])\n",
    "                aug_output_dict = self.model(aug_wavs)\n",
    "\n",
    "                for z, z_ in zip(output_dict['feature'], aug_output_dict['feature']):\n",
    "                    Z.append(z)\n",
    "                    Z_.append(z_)\n",
    "\n",
    "                clipwise_output = output_dict['clipwise_output']\n",
    "                pres = np.argmax(clipwise_output.detach().cpu(), axis=1)\n",
    "                target = np.argmax(data['target'].cpu(), axis=1)\n",
    "\n",
    "                for pre in pres: predict_list.append(pre.item())\n",
    "\n",
    "            class_label_dic = self.save_indexes(predict_list)\n",
    "        return Z, Z_, class_label_dic, predict_list\n",
    "    \n",
    "    def save_indexes(self,arr):\n",
    "        index_dict = {}\n",
    "        for idx, num in enumerate(arr):\n",
    "            if num in index_dict:\n",
    "                index_dict[num].append(idx)\n",
    "            else:\n",
    "                  index_dict[num] = [idx]\n",
    "        return index_dict\n",
    "\n",
    "    def class_infoNCE(self, Z, Z_, class_label_dic, predict_list, temperature):\n",
    "        ## You can change the method to calculate NCEs\n",
    "        NCEs = []\n",
    "        # print('This is cclass_label_dic',class_label_dic)\n",
    "        for id in range(len(predict_list)):\n",
    "            label = predict_list[id]\n",
    "            same_label_list = class_label_dic[label]\n",
    "            class_z = [Z[i] for i in same_label_list if i != id]\n",
    "            class_z_ = [Z_[i] for i in same_label_list]\n",
    "\n",
    "            positive_pair = class_z + class_z_\n",
    "\n",
    "            positive_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(positive_pair)) / 2 + 0.5\n",
    "            # print('This is postitive pair info',Z[id].unsqueeze(0).shape,torch.stack(positive_pair).shape,positive_similarities.shape)\n",
    "            positive_value = torch.exp(positive_similarities / temperature).sum() / len(positive_pair)\n",
    "            # print(positive_similarities,positive_value)\n",
    "            neg_labels = [i for i in list(class_label_dic.keys()) if i != label]\n",
    "\n",
    "            negative_values = 0\n",
    "            for neg_label in neg_labels:\n",
    "                neg_label_list = class_label_dic[neg_label]\n",
    "                neg_z = [Z[i] for i in neg_label_list]\n",
    "                neg_z_ = [Z_[i] for i in neg_label_list]\n",
    "                negative_pair = neg_z + neg_z_\n",
    "                negative_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(negative_pair)) / 2 + 0.5\n",
    "                # print('This is negative pair info',Z[id].unsqueeze(0).shape,torch.stack(negative_pair).shape,negative_similarities.shape,len(negative_pair))\n",
    "                negative_value = torch.exp(negative_similarities / temperature).sum() / len(negative_pair)\n",
    "                # print(negative_similarities,negative_value)\n",
    "                negative_values += negative_value\n",
    "\n",
    "            NCE = -torch.log(positive_value / (positive_value + negative_values))\n",
    "            # print('positive_value',positive_value,'negative values', negative_values,'this is single nce',NCE)\n",
    "            NCEs.append(NCE)\n",
    "        print(torch.stack(NCEs).shape)\n",
    "        return torch.stack(NCEs)\n",
    "    \n",
    "    def single_mutual_info_sampling(self, candidates, cur, num_class):\n",
    "        from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "        from collections import Counter\n",
    "        \n",
    "        class_list = [self.cltask[\"task0\"],self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "\n",
    "        ulclass_list =   [None,self.ultask[\"task1\"],self.ultask[\"task2\"],self.ultask[\"task3\"],self.ultask[\"task4\"]]\n",
    "        cur_class_list = []\n",
    "        for i in range(num_class // 13):\n",
    "            cur_class_list |= set(class_list[i])\n",
    "            cur_class_list -= set(ulclass_list[i])\n",
    "            \n",
    "\n",
    "        # Unlearning Part:class deleted will not be added into the memory bank\n",
    "\n",
    "        infer_df = pd.DataFrame(candidates)\n",
    "\n",
    "        class_count = Counter(infer_df['category'])\n",
    "        print('Before Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "        # mem_per_cls = self.memory_size // num_class  # kc: the number of the samples of each class\n",
    "\n",
    "        batch_size = 8\n",
    "        temperature = 0.05\n",
    "        ret = []\n",
    "        infer_loader = get_dataloader(infer_df, 'ref_youtube_audio', split='test', batch_size=batch_size, num_class=num_class,\n",
    "                                      num_workers=8)\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur - 1)\n",
    "        self.change_model(path)\n",
    "\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur)\n",
    "        self.change_model(path)\n",
    "\n",
    "        # print(len(Z),len(Z_),len(predict_list),len(candidates))\n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        for candidate,NCE in zip(candidates,NCEs):candidate['NCE'] = NCE\n",
    "\n",
    "        sample_df = pd.DataFrame(candidates)\n",
    "\n",
    "        mem_per_cls = self.memory_size // cur_class_list  # kc: the number of the samples of each class\n",
    "\n",
    "\n",
    "        for i in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret)['category'])\n",
    "        print('After Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def double_mutual_info_sampling(self, candidates, cur, num_class):\n",
    "        from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "        from collections import Counter\n",
    "        \n",
    "        ulclass_list =   [None,self.ultask[\"task1\"],self.ultask[\"task2\"],self.ultask[\"task3\"],self.ultask[\"task4\"]]\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cl_class_list = []\n",
    "        ul_class_list = []\n",
    "        for i in range(num_class // 13):\n",
    "            cur_class_list |= set(class_list[i])\n",
    "            cur_class_list -= set(ulclass_list[i])\n",
    "        cur_class_list.add(self.total_class_num-1)\n",
    "        # Unlearning Part:class deleted will not be added into the memory bank\n",
    "\n",
    "        infer_df = pd.DataFrame(candidates)\n",
    "\n",
    "        class_count = Counter(infer_df['category'])\n",
    "        print('Before Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "        # mem_per_cls = self.memory_size // num_class  # kc: the number of the samples of each class\n",
    "\n",
    "        batch_size = 8\n",
    "        temperature = 0.05\n",
    "        ret = []\n",
    "        infer_loader = get_dataloader(infer_df, 'ref_youtube_audio', split='test', batch_size=batch_size, num_class=num_class,\n",
    "                                      num_workers=8)\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur - 1)\n",
    "        self.change_model(path)\n",
    "\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur)\n",
    "        self.change_model(path)\n",
    "\n",
    "        # print(len(Z),len(Z_),len(predict_list),len(candidates))\n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        for candidate,NCE in zip(candidates,NCEs):candidate['NCE'] = NCE\n",
    "\n",
    "        sample_df = pd.DataFrame(candidates)\n",
    "         # kc: the number of the samples of each class in memory bank\n",
    "        mem_per_cls = self.memory_size // len(cl_class_list)\n",
    "        \n",
    "        for_per_cls = self.forget_size// len(ul_class_list)\n",
    "        \n",
    "\n",
    "\n",
    "        for i in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        # top_indices = np.argpartition(NCEs.cpu().numpy(), -2000)[-2000:]\n",
    "        #\n",
    "        # for index in top_indices:\n",
    "        #     ret.append(candidates[index])\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret)['category'])\n",
    "        print('After Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "\n",
    "        return ret\n",
    "    def train_with_forget_without_forget_bank(self, cur_iter,):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28552e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c861e3630664acb966119eabd4f657a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Batch 0 Loss: 139.34771728515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m clul \u001b[38;5;241m=\u001b[39m CLUL()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# clul.model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mclul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 88\u001b[0m, in \u001b[0;36mCLUL.train\u001b[1;34m(self, cur_iter)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[0;32m     87\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(batch_output_dict, batch_target_dict)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch Training Initial Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\torch\\_tensor.py:659\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta:\n\u001b[1;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_list,test_list = get_datalist(0)\n",
    "# train_loader ,test_loader = get_train_test_dataloader(16,0,train_list,test_list)\n",
    "\n",
    "# for train in train_loader:\n",
    "#     print(train)\n",
    "clul = CLUL()\n",
    "# clul.model\n",
    "clul.train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7466bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 33/33 [01:06<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 | Evaluation Accuracy: [-0.         -0.         -0.         -0.          0.09636835 -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.40476822 -0.          0.07345214\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.24198703  0.81692732 -0.         -0.         -0.         -0.\n",
      " -0.          0.14969995  0.77455172 -0.         -0.         -0.\n",
      "  0.11510492 -0.         -0.         -0.          0.53467356 -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.71869161 -0.          0.3301716  -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.24848273 -0.         -0.          0.03364166 -0.        ]|Evaluation f1_score: 0.008652134562156525|Evaluation precision 0.06031128404669261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clul = CLUL()\n",
    "clul.evaluate(r'C:\\Users\\Administrator\\Desktop\\CLUL-main\\run\\CLUL _no_foget_bank\\task0best_epoch0.pt',cur_iter=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3d49df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bb0f7-8fe9-443c-a62c-04a0d6fb0fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "CLUL38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
