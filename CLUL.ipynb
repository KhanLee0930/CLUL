{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf742fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If U are using SageMaker Prepare for the dataset\n",
    "!pip install awscli\n",
    "!aws s3 cp s3://handata/ref_youtube_audio/ ref_youtube_audio/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -U openai-whisper\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e7a758-d85d-444c-aede-9f31a6fe37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, WhisperForAudioClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from categories import ytvos_category_dict\n",
    "import numpy as np\n",
    "from util import read_aws_json,read_aws_wav,read_local_json,read_local_wav\n",
    "import logging\n",
    "from torch import optim\n",
    "from losses import get_loss_func\n",
    "from utils.evaluate import Evaluator\n",
    "from util import infoNCE_loss\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from enum import Enum\n",
    "from sklearn.metrics import f1_score,precision_recall_curve,precision_score,recall_score,accuracy_score,balanced_accuracy_score\n",
    "from collections import Counter\n",
    "from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "SageMaker = False\n",
    "Local = True\n",
    "# ROOT = 'C:/Users/Administrator/Desktop/CLUL-main/data/'\n",
    "# SAVEDIR = 'C:/Users/Administrator/Desktop/CLUL-main/run/'\n",
    "ROOT = '/root/CLUL/data/'\n",
    "SAVEDIR = '/root/CLUL/run/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a734c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Audio_Encoder(nn.Module):\n",
    "    def __init__(self, feature_extractor, model, num_class=66,dropout_prob=0.2,pool_num = 100,bias = True):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.encoder = model.encoder\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "          param.requires_grad = False\n",
    "        self.projector = nn.Linear(in_features=768, out_features=256, bias=True)\n",
    "        self.classifier = nn.Linear(256, num_class)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(pool_num,1), stride=(pool_num,1))\n",
    "        # self.norm_layer = nn.LayerNorm(256, eps=1e-5, bias=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(2048, affine=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(1500//pool_num * 256, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 256)\n",
    "        self.fc3 = nn.Linear(256, num_class)\n",
    "\n",
    "    def forward(self, audios):\n",
    "        input_features = []\n",
    "        for audio in audios:\n",
    "\n",
    "            feature = self.feature_extractor(audio.cpu(),sampling_rate=16000,return_tensors=\"pt\").input_features\n",
    "            input_features.append(feature)\n",
    "\n",
    "        input_features = torch.cat(input_features, dim=0).to(self.device)\n",
    "        hidden_states = self.encoder(input_features)\n",
    "        # hidden_states = self.projector(hidden_states)\n",
    "        # pooled_output = hidden_states.mean(dim=1)\n",
    "        # logits = self.classifier(pooled_output)\n",
    "\n",
    "        x = self.avg_pool(hidden_states)\n",
    "\n",
    "        x = self.projector(x)\n",
    "        # x = self.positionencoding(x)\n",
    "        feature = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(feature)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        output_dict = {\n",
    "            'clipwise_output': x,\n",
    "            'feature': feature,\n",
    "            'embedding': hidden_states}\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "class ytvos_Dataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame, sr=44100, num_class=66):\n",
    "        self.data_frame = data_frame\n",
    "        self.sr = sr\n",
    "        self.num_class = num_class\n",
    "        self.data_root = '/home/user/SED_Adaptation_Classifier-main/data/ref_youtube_audio/audio'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        audio_name = self.data_frame.iloc[index][\"video\"]\n",
    "        audio_id = self.data_frame.iloc[index][\"audio\"]\n",
    "        audio_path = 'ref_youtube_audio/audio' + '/' + audio_name + '/' + audio_id + '.wav'\n",
    "        name = audio_name + self.data_frame.iloc[index][\"exp\"]\n",
    "\n",
    "        \n",
    "        waveform = read_local_wav(ROOT + audio_path)\n",
    "#         waveform = whisper.load_audio(audio_path,sr = 16000)\n",
    "\n",
    "        tag = self.data_frame.iloc[index][\"category\"]\n",
    "        target = ytvos_category_dict[self.data_frame.iloc[index][\"category\"]]\n",
    "        target = np.eye(self.num_class)[target]\n",
    "        data_dict = {'audio_name': name, 'waveform': waveform, 'target': target, 'tag': tag}\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "def get_datalist(cur_iter):\n",
    "        task_id = cur_iter\n",
    "        task_train_metas = []\n",
    "        task_test_metas = []\n",
    "\n",
    "       \n",
    "        metas = read_local_json(ROOT + 'task_split_1/metas.json')['metas']\n",
    "        tasks = read_local_json(ROOT + 'task_split_1/task{}.json'.format(task_id))[str(task_id)]\n",
    "\n",
    "        for category,task_metas_dict in tasks.items():\n",
    "            train_ids = task_metas_dict['train']\n",
    "            test_ids = task_metas_dict['test']\n",
    "            for train_id in train_ids:\n",
    "                task_train_metas.append(metas[train_id])\n",
    "            for test_id in test_ids:\n",
    "                task_test_metas.append(metas[test_id])\n",
    "\n",
    "        return task_train_metas,task_test_metas\n",
    "    \n",
    "def default_collate_fn(batch):\n",
    "    audio_name = [data['audio_name'] for data in batch]\n",
    "    waveform = [torch.from_numpy(data['waveform']) for data in batch]\n",
    "    target = [data['target'] for data in batch]\n",
    "\n",
    "    # waveform = torch.FloatTensor(waveform)\n",
    "    # waveform = pad_sequence(waveform, batch_first=True, padding_value=0)\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    return {'audio_name': audio_name, 'waveform': waveform, 'target': target}\n",
    "\n",
    "def get_dataloader(data_frame, dataset,split, batch_size, num_workers=0):\n",
    "    assert dataset == \"ref_youtube_audio\"\n",
    "    dataset = ytvos_Dataset(data_frame=data_frame)\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                      shuffle=(split == 'train'), drop_last=False,\n",
    "                      num_workers=num_workers, collate_fn=default_collate_fn)\n",
    "\n",
    "def get_train_test_dataloader(batch_size, n_worker, train_list, test_list):\n",
    "    train_loader = get_dataloader(pd.DataFrame(train_list), 'ref_youtube_audio','train', batch_size=batch_size, \n",
    "                                  num_workers=n_worker)\n",
    "    test_loader = get_dataloader(pd.DataFrame(test_list), 'ref_youtube_audio','test', batch_size=batch_size, \n",
    "                                 num_workers=n_worker)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d6cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLUL:\n",
    "    def __init__(self,batch_size = 32,lr = 1e-3,memory_size = 500,\n",
    "                 forget_size = 100,epoch=3,loss ='focal_loss',\n",
    "                 total_class_num = 65,mode = 'All_Learn_then_Forget',\n",
    "                 patience = 2,n_worker = 0,\n",
    "                 **kwargs):\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"/root/CLUL/whisper\")\n",
    "        whisper_model = whisper.load_model(\"small\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = Audio_Encoder(feature_extractor, whisper_model).to(self.device)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.logger = logging.getLogger()\n",
    "        self.forget_list = []\n",
    "        self.memory_list = []\n",
    "        self.memory_size = memory_size\n",
    "        self.forget_size = forget_size\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas=(0.9, 0.999))\n",
    "        self.scheduler = ExponentialLR(self.optimizer, gamma=0.9)\n",
    "        self.criterion = get_loss_func(loss)\n",
    "        self.num_pretrain_class = 0\n",
    "        self.evaluator = Evaluator(self.model, self.num_pretrain_class, self.device)\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.total_class_num = total_class_num\n",
    "        self.forget_label = total_class_num\n",
    "        self.n_worker = n_worker\n",
    "        self.cltask = {\n",
    "            'task0':[15, 17, 60, 50, 32, 24, 63, 36, 31, 40, 52, 4, 25],\n",
    "            \"task1\":[48, 54, 35, 62, 13, 42, 37, 49, 51, 45, 44, 14, 5],\n",
    "            \"task2\":[46, 18, 57, 28, 11, 30, 61, 27, 22, 2, 29, 0, 19],\n",
    "            \"task3\":[3, 59, 10, 12, 8, 1, 26, 23, 34, 58, 64, 56, 41],\n",
    "            \"task4\":[47, 20, 53, 39, 9, 21, 16, 38, 33, 43, 6, 7, 55]\n",
    "        }\n",
    "        self.ultask = {\n",
    "            \"ul_task0\":[],\n",
    "            \"ul_task1\":[15,17,60],\n",
    "            \"ul_task2\": [48, 54, 35],\n",
    "            \"ul_task3\":[46, 18, 57],\n",
    "            \"ul_task4\" : [3, 59, 10],\n",
    "            \"ul_task5\" : [47, 20, 53]\n",
    "        }\n",
    "           \n",
    "    def evaluate(self,model_path,cur_iter):\n",
    "        self.change_model(model_path)\n",
    "        train_list,test_list = self.get_train_test_datalist(cur_iter)\n",
    "        _, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "        \n",
    "        cl_class_label,ul_class_label = self.get_cl_ul_class_label(cur_iter)\n",
    "        # statistics = self.calculate_metrics(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "        # print(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "        # return statistics\n",
    "        return y_true,y_pred,cl_class_label,ul_class_label\n",
    "\n",
    "    def get_train_test_datalist(self,cur_iter):\n",
    "        train_list,test_list = get_datalist(cur_iter)\n",
    "        return train_list,test_list\n",
    "        \n",
    "    def change_model(self, path):\n",
    "        checkpoint_dict = torch.load(path)\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if name in checkpoint_dict:\n",
    "                    param.data.copy_(checkpoint_dict[name])\n",
    "                \n",
    "    def equal_class_sampling(self, samples, num_class):\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cur_class_list = []\n",
    "        for i in range(num_class//13):\n",
    "            cur_class_list += class_list[i]\n",
    "        mem_per_cls = self.memory_size // num_class\n",
    "        sample_df = pd.DataFrame(samples)\n",
    "\n",
    "        # Warning: assuming the classes were ordered following task number.\n",
    "        ret = []\n",
    "        for y in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == y]\n",
    "            ret += cls_df.sample(n=min(mem_per_cls, len(cls_df))).to_dict(\n",
    "                orient=\"records\"\n",
    "            )\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            self.logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            self.logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_data(self, infer_loader, augment):\n",
    "        Z, Z_, predict_list = [], [], []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for id, data in enumerate(tqdm(infer_loader)):\n",
    "                wavs = data['waveform']\n",
    "                aug_wavs = []\n",
    "                for wav in wavs:\n",
    "                    aug_wav = augment(wav.unsqueeze(0).unsqueeze(0), sample_rate=1600)\n",
    "                    aug_wavs.append(torch.as_tensor(aug_wav.squeeze(0).squeeze(0), dtype=torch.float32))\n",
    "\n",
    "                output_dict = self.model(data['waveform'])\n",
    "                aug_output_dict = self.model(aug_wavs)\n",
    "\n",
    "                Z.extend(output_dict['feature'].cpu())\n",
    "                Z_.extend(aug_output_dict['feature'].cpu())\n",
    "\n",
    "                clipwise_output = output_dict['clipwise_output']\n",
    "                pres = np.argmax(clipwise_output.detach().cpu(), axis=1)\n",
    "                \n",
    "\n",
    "                for pre in pres: predict_list.append(pre.item())\n",
    "\n",
    "            class_label_dic = self.save_indexes(predict_list)\n",
    "        return Z, Z_, class_label_dic, predict_list\n",
    "    \n",
    "    def save_indexes(self,arr):\n",
    "        index_dict = {}\n",
    "        for idx, num in enumerate(arr):\n",
    "            if num in index_dict:\n",
    "                index_dict[num].append(idx)\n",
    "            else:\n",
    "                  index_dict[num] = [idx]\n",
    "        return index_dict\n",
    "\n",
    "    def forget_label_set(self,y_true,ul_class_label):\n",
    "        index_row = torch.argmax(y_true,dim=1)\n",
    "        for r ,c in enumerate(index_row):\n",
    "            if int(c) in ul_class_label:\n",
    "                with torch.no_grad():\n",
    "                    y_true[r][c] = torch.tensor(0.0, dtype=torch.float32)\n",
    "                    y_true[r][-1] = torch.tensor(1.0, dtype=torch.float32)\n",
    "        return y_true\n",
    "    \n",
    "    def class_infoNCE(self, Z, Z_, class_label_dic, predict_list, temperature):\n",
    "        ## You can change the method to calculate NCEs\n",
    "        NCEs = []\n",
    "        # print('This is cclass_label_dic',class_label_dic)\n",
    "        for id in range(len(predict_list)):\n",
    "            label = predict_list[id]\n",
    "            same_label_list = class_label_dic[label]\n",
    "            class_z = [Z[i] for i in same_label_list if i != id]\n",
    "            class_z_ = [Z_[i] for i in same_label_list]\n",
    "\n",
    "            positive_pair = class_z + class_z_\n",
    "\n",
    "            positive_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(positive_pair)) / 2 + 0.5\n",
    "            # print('This is postitive pair info',Z[id].unsqueeze(0).shape,torch.stack(positive_pair).shape,positive_similarities.shape)\n",
    "            positive_value = torch.exp(positive_similarities / temperature).sum() / len(positive_pair)\n",
    "            # print(positive_similarities,positive_value)\n",
    "            neg_labels = [i for i in list(class_label_dic.keys()) if i != label]\n",
    "\n",
    "            negative_values = 0\n",
    "            for neg_label in neg_labels:\n",
    "                neg_label_list = class_label_dic[neg_label]\n",
    "                neg_z = [Z[i] for i in neg_label_list]\n",
    "                neg_z_ = [Z_[i] for i in neg_label_list]\n",
    "                negative_pair = neg_z + neg_z_\n",
    "                negative_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(negative_pair)) / 2 + 0.5\n",
    "                # print('This is negative pair info',Z[id].unsqueeze(0).shape,torch.stack(negative_pair).shape,negative_similarities.shape,len(negative_pair))\n",
    "                negative_value = torch.exp(negative_similarities / temperature).sum() / len(negative_pair)\n",
    "                # print(negative_similarities,negative_value)\n",
    "                negative_values += negative_value\n",
    "\n",
    "            NCE = -torch.log(positive_value / (positive_value + negative_values))\n",
    "            # print('positive_value',positive_value,'negative values', negative_values,'this is single nce',NCE)\n",
    "            NCEs.append(NCE)\n",
    "        print(torch.stack(NCEs).shape)\n",
    "        return torch.stack(NCEs)\n",
    "    \n",
    "    def single_mutual_info_sampling(self,cur_iter, train_list, cl_class_label, ul_class_label):\n",
    "        ret_mem = []\n",
    "        val_class_label = list(set(cl_class_label) - set(ul_class_label))\n",
    "        train_df = pd.DataFrame(train_list)\n",
    "        train_df['category_id'] = train_df['category'].map(ytvos_category_dict)\n",
    "\n",
    "        train_df = train_df[train_df['category_id']. isin( val_class_label)]\n",
    "        assert len(Counter(train_df['category'])) == len(val_class_label)\n",
    "\n",
    "        inf_loader = get_dataloader(train_df, 'ref_youtube_audio', 'test', self.batch_size, self.n_worker)\n",
    "        temperature = 0.05\n",
    "\n",
    "\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        #Calculate current infoNCE\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(inf_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "\n",
    "        #Calculate previous infoNCE\n",
    "\n",
    "        self.change_model(SAVEDIR + '{}/task{}best_epoch2.pt'.format(self.mode,cur_iter-1))\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(inf_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "        self.change_model(SAVEDIR + '{}/task{}best_epoch2.pt'.format(self.mode,cur_iter))\n",
    "\n",
    "        \n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        train_df['NCE'] = NCEs\n",
    "\n",
    "        mem_per_cls = self.memory_size // len(val_class_label)\n",
    "\n",
    "        for i in val_class_label:\n",
    "            cls_df = train_df[(train_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret_mem += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret_mem += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret_mem)\n",
    "        if num_rest_slots > 0:\n",
    "            self.logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret_mem += (\n",
    "                train_df[~train_df.exp.isin(pd.DataFrame(ret_mem).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret_mem).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            self.logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret_mem)['category'])\n",
    "        print('After Unpdate Statistics',class_count)\n",
    "        \n",
    "        return ret_mem\n",
    "      \n",
    "    def double_mutual_info_sampling(self, candidates, cur, num_class):\n",
    "        from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "        from collections import Counter\n",
    "        \n",
    "        ulclass_list =   [None,self.ultask[\"task1\"],self.ultask[\"task2\"],self.ultask[\"task3\"],self.ultask[\"task4\"]]\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cl_class_list = []\n",
    "        ul_class_list = []\n",
    "        for i in range(num_class // 13):\n",
    "            cur_class_list |= set(class_list[i])\n",
    "            cur_class_list -= set(ulclass_list[i])\n",
    "        cur_class_list.add(self.total_class_num-1)\n",
    "        # Unlearning Part:class deleted will not be added into the memory bank\n",
    "\n",
    "        infer_df = pd.DataFrame(candidates)\n",
    "\n",
    "        class_count = Counter(infer_df['category'])\n",
    "        print('Before Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "        # mem_per_cls = self.memory_size // num_class  # kc: the number of the samples of each class\n",
    "\n",
    "        batch_size = 8\n",
    "        temperature = 0.05\n",
    "        ret = []\n",
    "        infer_loader = get_dataloader(infer_df, 'ref_youtube_audio', split='test', batch_size=batch_size, num_class=num_class,\n",
    "                                      num_workers=8)\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur - 1)\n",
    "        self.change_model(path)\n",
    "\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur)\n",
    "        self.change_model(path)\n",
    "\n",
    "        # print(len(Z),len(Z_),len(predict_list),len(candidates))\n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        for candidate,NCE in zip(candidates,NCEs):candidate['NCE'] = NCE\n",
    "\n",
    "        sample_df = pd.DataFrame(candidates)\n",
    "         # kc: the number of the samples of each class in memory bank\n",
    "        mem_per_cls = self.memory_size // len(cl_class_list)\n",
    "        \n",
    "        for_per_cls = self.forget_size// len(ul_class_list)\n",
    "        \n",
    "\n",
    "\n",
    "        for i in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        # top_indices = np.argpartition(NCEs.cpu().numpy(), -2000)[-2000:]\n",
    "        #\n",
    "        # for index in top_indices:\n",
    "        #     ret.append(candidates[index])\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret)['category'])\n",
    "        print('After Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def train_with_datalist(self,train_list,test_list):\n",
    "        \n",
    "        train_loader, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        self.logger.info(f\"In-memory samples: {len(self.memory_list)}\")\n",
    "        self.logger.info(f\"Train samples: {len(train_list)}\")\n",
    "        self.logger.info(f\"Test samples: {len(test_list)}\")\n",
    "        # logger.info(f\"Model: {self.model}\")\n",
    "        self.logger.info(f\"Optimizer: {self.optimizer}\")\n",
    "        acc_list = []\n",
    "        best = {'acc': 0, 'epoch': 0,'f1_score':0}\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            self.logger.info(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            test_statistics = self.evaluator.evaluate(test_loader)\n",
    "            ave_f1_score = np.mean(test_statistics['f1_score'])\n",
    "            ave_acc = np.mean(test_statistics['accuracy'])\n",
    "            acc_list.append(ave_acc)\n",
    "            self.logger.info(f\"Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}\")\n",
    "            self.logger.info(f'Current Accuracy: {ave_acc} in epoch {epoch}.|Current f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "            print(f\"Task {cur_iter} | Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}|Evaluation precision {test_statistics['precision']}\")\n",
    "            \n",
    "\n",
    "            if ave_f1_score > best['f1_score']:\n",
    "                best['acc'] = ave_acc\n",
    "                best['f1_score'] = ave_f1_score\n",
    "                best['epoch'] = epoch\n",
    "                self.logger.info(f'Best Accuracy: {ave_acc} in epoch {epoch}.|Best f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Evaluation Accuracy: {best['acc']}|Evaluation f1_score: {best['f1_score']}\")\n",
    "        return \n",
    "    \n",
    "    def calculate_metrics(self,y_true,y_pred,cl_class_label,ul_class_label):\n",
    "        statistics = {'cl_weighted_accuracy':0,'ul_weighted_accuracy':0,'cl_accuracy':0,'ul_accuracy':0}\n",
    "        cl_y_true,cl_y_pred = [],[]\n",
    "        ul_y_true,ul_y_pred = [],[]\n",
    "        for y_t,y_d in zip(y_true,y_pred):\n",
    "            if y_t in cl_class_label and y_t not in ul_class_label:\n",
    "                cl_y_true.append(y_t)\n",
    "                cl_y_pred.append(y_d)\n",
    "            else:\n",
    "                ul_y_true.append(y_t)\n",
    "                ul_y_pred.append(y_d)\n",
    "\n",
    "        cl_weighted_accuracy = balanced_accuracy_score(cl_y_true,cl_y_pred)\n",
    "        ul_weighted_accuracy = balanced_accuracy_score(ul_y_true,ul_y_pred)\n",
    "\n",
    "        cl_accuracy = accuracy_score(cl_y_true,cl_y_pred)\n",
    "        ul_accuracy = accuracy_score(ul_y_true,ul_y_pred)\n",
    "\n",
    "        statistics['ul_accuracy'] = ul_accuracy\n",
    "        statistics['cl_accuracy'] = cl_accuracy\n",
    "\n",
    "        statistics['cl_weighted_accuracy'] = cl_weighted_accuracy\n",
    "        statistics['ul_weighted_accuracy'] = ul_weighted_accuracy\n",
    "        # print(cl_y_true,cl_y_pred)\n",
    "        # print(ul_y_true,ul_y_pred)\n",
    "        return statistics\n",
    "\n",
    "    def get_cl_ul_class_label(self,cur_iter):\n",
    "        cl_class_label = self.cltask[f'task{cur_iter}']\n",
    "        ul_class_label = self.ultask[f'ul_task{cur_iter}']\n",
    "        return cl_class_label,ul_class_label\n",
    "    \n",
    "    def train_with_forget_without_forget_bank(self, cur_iter,mode = 'all_learn_forget'):\n",
    "        \n",
    "        memory_bank = self.memory_list\n",
    "        test_list = []\n",
    "        for i in range(cur_iter + 1):\n",
    "            train_list_,test_data_list_ = get_datalist(i)\n",
    "            test_list += test_data_list_\n",
    "        \n",
    "        train_list,_ = get_datalist(cur_iter)\n",
    "        train_list += memory_bank\n",
    "\n",
    "        train_loader,test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        cl_class_label,ul_class_label = [],[]\n",
    "\n",
    "        best = {'cl_weighted_accuracy':0,'cl_accuracy':0,'ul_weighted_accuracy':0,'ul_accuracy':0,'epoch':0}\n",
    "        for i in range(cur_iter + 1):\n",
    "            cl_class_label += self.cltask[f'task{i}']\n",
    "            ul_class_label += self.ultask[f'ul_task{i}']\n",
    "        print('train loader length',len(train_loader),'test loader length',len(test_loader),'cl class label',cl_class_label,'ul class label',ul_class_label)\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                # print(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = self.forget_label_set(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            \n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "\n",
    "            statistics = self.calculate_metrics(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "\n",
    "            print(f\"Task {cur_iter} |  Epoch {epoch} | statistics {statistics}\")\n",
    "            if  statistics['cl_weighted_accuracy'] > best['cl_weighted_accuracy']:\n",
    "                best['cl_weighted_accuracy'] = statistics['cl_weighted_accuracy']\n",
    "                best['cl_accuracy'] = statistics['cl_accuracy']\n",
    "                best['epoch'] = epoch\n",
    "                # self.logger.info(f'Best Accuracy: {accuracy} in epoch {epoch}.|Best weighted_accuracy: {weighted_accuracy} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Accuracy: {best['cl_accuracy']}|Best weighted_accuracy: {best['cl_weighted_accuracy']}\")\n",
    "        return train_list,test_list,cl_class_label,ul_class_label\n",
    "    \n",
    "    def train(self,mode,train_list,test_list,cl_class_label,ul_class_label,cur_iter):\n",
    "        \n",
    "        train_loader,test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "\n",
    "        best = {'epoch':0,'cl_weighted_accuracy':0,'ul_weighted_accuracy':0,'cl_accuracy':0,'ul_accuracy':0}\n",
    "        print('train loader length',len(train_loader),'test loader length',len(test_loader),'cl class label',cl_class_label,'ul class label',ul_class_label)\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                # print(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = self.forget_label_set(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            \n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "            \n",
    "            statistics = self.calculate_metrics(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "            if mode == 'All_Learn_then_Forget':\n",
    "                statistics = self.calculate_metrics(y_true,y_pred,[i for i in range(65)],ul_class_label)\n",
    "            print(f\"Task {cur_iter} |  Current Epoch {epoch} | statistics {statistics}\")\n",
    "            if  statistics['cl_weighted_accuracy'] > best['cl_weighted_accuracy']:\n",
    "                best['cl_weighted_accuracy'] = statistics['cl_weighted_accuracy']\n",
    "                best['cl_accuracy'] = statistics['cl_accuracy']\n",
    "                best['epoch'] = epoch\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch.pt'.format(self.mode,cur_iter))\n",
    "                print('Save Model Successfully',SAVEDIR + '{}/task{}best_epoch.pt'.format(self.mode,cur_iter))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "            self.scheduler.step()\n",
    "        print(f\"Task {cur_iter} | Best epoch  Best Statistics {best}\")\n",
    "        y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "        return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b97116b-66f5-41aa-957c-4637ee8a2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Training and each stage forget\n",
    "#Each Stage train the all Data Need to Remember and all Data Need to be Forget(Memory bank full,Forget bank full)\n",
    "def Step_Learn_Froeget_Full_memory_Full_forget():\n",
    "    clul = CLUL(epoch = 10)\n",
    "    for idx in range(5):\n",
    "        clul.train_with_forget_without_forget_bank(idx)\n",
    "        train_list,_ = clul.get_train_test_datalist(0)\n",
    "        clul.memory += train_list\n",
    "\n",
    "#At Last Stage learn and forget together\n",
    "def All_Learn_Forget_No_memory_No_forget():\n",
    "    clul = CLUL(epoch = 10)\n",
    "    train_list,test_list = [],[]\n",
    "    cl_class_label,ul_class_label = [],[]\n",
    "    for idx in range(5):\n",
    "        train_list_,test_list_ = clul.get_train_test_datalist(idx)\n",
    "        cl_class_label_,ul_class_label_ =clul.get_cl_ul_class_label(idx)\n",
    "        train_list += train_list_\n",
    "        test_list += test_list_\n",
    "        cl_class_label += cl_class_label_\n",
    "        ul_class_label += ul_class_label_\n",
    "        \n",
    "    print('train list length',len(train_list),'test list length',len(test_list),\n",
    "      'cl class label length',len(cl_class_label),'ul class label length',len(ul_class_label))\n",
    "    clul.train('All_Learn_Forget_No_memory_No_forget',train_list,test_list,cl_class_label,ul_class_label,4)\n",
    "\n",
    "def All_Learn_then_Forget():\n",
    "    clul = CLUL(epoch = 5,mode='All_Learn_then_Forget')\n",
    "    train_list,test_list = [],[]\n",
    "    cl_class_label,ul_class_label = [],[]\n",
    "    for idx in range(5):\n",
    "        train_list_,test_list_ = clul.get_train_test_datalist(idx)\n",
    "        cl_class_label_,ul_class_label_ =clul.get_cl_ul_class_label(idx)\n",
    "        train_list += train_list_\n",
    "        test_list += test_list_\n",
    "        cl_class_label += cl_class_label_\n",
    "        \n",
    "    print('train list length',len(train_list),'test list length',len(test_list),\n",
    "      'cl class label length',len(cl_class_label),'ul class label length',len(ul_class_label))\n",
    "    clul.train('All_Learn_then_Forget',train_list,test_list,cl_class_label,ul_class_label,4)\n",
    "\n",
    "    \n",
    "    train_list,test_list = [],[]\n",
    "    cl_class_label,ul_class_label = [],[]\n",
    "    for idx in range(5):\n",
    "        train_list_,test_list_ = clul.get_train_test_datalist(idx)\n",
    "        cl_class_label_,ul_class_label_ =clul.get_cl_ul_class_label(idx)\n",
    "        train_list += train_list_\n",
    "        test_list += test_list_\n",
    "        ul_class_label += ul_class_label\n",
    "    \n",
    "    train_list = pd.DataFrame(train_list)[(pd.DataFrame(train_list)[\"category\"].map(ytvos_category_dict)).isin(ul_class_label)].to_dict(orient=\"records\")\n",
    "    print('train list length',len(train_list),'test list length',len(test_list),\n",
    "      'cl class label length',len(cl_class_label),'ul class label length',len(ul_class_label))\n",
    "    clul.train('All_Learn_then_Forget',train_list,test_list,cl_class_label,ul_class_label,4)\n",
    "def All_Forget():\n",
    "    clul = CLUL(epoch = 1,mode='All_Learn_then_Forget')\n",
    "    clul.change_model('/root/CLUL/run/All_Learn_then_Forget/task4best_epoch1.pt')\n",
    "     \n",
    "    train_list,test_list = [],[]\n",
    "    cl_class_label,ul_class_label = [],[35]\n",
    "    \n",
    "    for idx in range(5):\n",
    "        train_list_,test_list_ = clul.get_train_test_datalist(idx)\n",
    "        cl_class_label_,ul_class_label_ =clul.get_cl_ul_class_label(idx)\n",
    "        train_list += train_list_\n",
    "        test_list += test_list_\n",
    "        \n",
    "    ul_class_label = list(set(ul_class_label))\n",
    "    \n",
    "    train_list = pd.DataFrame(train_list)[(pd.DataFrame(train_list)[\"category\"].map(ytvos_category_dict)).isin(ul_class_label)].to_dict(orient=\"records\")\n",
    "    print('forget train list length',len(train_list),'test list length',len(test_list),\n",
    "      'cl class label length',len(cl_class_label),'ul class label length',len(ul_class_label))\n",
    "    \n",
    "    y_true,y_false = clul.train('All_Learn_then_Forget',train_list,test_list,cl_class_label,ul_class_label,4)\n",
    "    return y_true,y_false\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726e2d6-a3b6-4bfd-b0c6-349772f6f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the last stage learn all and forget all together \n",
    "All_Learn_Forget_No_memory_No_forget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df90c27-fe70-4b07-92f6-d2af1dd2be8a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget train list length 87 test list length 2494 cl class label length 0 ul class label length 1\n",
      "train loader length 3 test loader length 78 cl class label [] ul class label [35]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de76620caef473ab851050a0df381ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Batch 0 Loss: 36.2474365234375\n",
      "Epoch 0 | Training Loss: 454.7885962327321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 78/78 [01:11<00:00,  1.10it/s]\n",
      "/root/miniconda3/envs/CLUL/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/root/miniconda3/envs/CLUL/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/root/miniconda3/envs/CLUL/lib/python3.8/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/root/miniconda3/envs/CLUL/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/root/miniconda3/envs/CLUL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned target_acc and clipwise_output_acc\n",
      "Task 4 |  Current Epoch 0 | statistics {'cl_weighted_accuracy': 0.2905311057022558, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.5311488673139159, 'ul_accuracy': 0.0}\n",
      "Save Model Successfully /root/CLUL/run/All_Learn_then_Forget/task4best_epoch.pt\n",
      "Task 4 | Best epoch  Best Statistics {'epoch': 0, 'cl_weighted_accuracy': 0.2905311057022558, 'ul_weighted_accuracy': 0, 'cl_accuracy': 0.5311488673139159, 'ul_accuracy': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 78/78 [01:12<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned target_acc and clipwise_output_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([15, 15, 15, ..., 55, 55, 55]), array([15, 42, 42, ..., 55, 55, 42]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In the last stage learn all then forget all \n",
    "# All_Learn_then_Forget()\n",
    "forget_all = [35, 3, 10, 46, 15, 48, 17, 18, 54, 57, 59, 60]\n",
    "All_Forget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e06939-1355-49a7-9924-682649a99472",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clul' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclul\u001b[49m\u001b[38;5;241m.\u001b[39mcalculate_metrics(y_true,y_pred,[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m65\u001b[39m)],[\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m54\u001b[39m, \u001b[38;5;241m57\u001b[39m, \u001b[38;5;241m59\u001b[39m, \u001b[38;5;241m60\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clul' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "clul.calculate_metrics(y_true,y_pred,[i for i in range(65)],[35, 3, 10, 46, 15, 48, 17, 18, 54, 57, 59, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22803a-2ed3-4a2b-810c-e69f52445c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab015a-9634-4fd6-b77b-ff4e8b93d8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f418b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list1,test_list1 = clul.get_train_test_datalist(0)\n",
    "cl_class_label1,ul_class_label1 = clul.get_cl_ul_class_label(0)\n",
    "\n",
    "train_list2,test_list2 = clul.get_train_test_datalist(1)\n",
    "cl_class_label2,ul_class_label2 = clul.get_cl_ul_class_label(1)\n",
    "\n",
    "train_list = train_list1 + train_list2\n",
    "cl_class_label = cl_class_label1 + cl_class_label2\n",
    "ul_class_label = ul_class_label1 + ul_class_label2\n",
    "\n",
    "\n",
    "clul.change_model(r'C:\\Users\\Administrator\\Desktop\\CLUL-main\\run\\CLUL _no_foget_bank\\task1best_epoch2.pt')\n",
    "memory = clul.single_mutual_info_sampling(1,train_list,cl_class_label,ul_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d49df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class_label_dic\n",
    "train_list,test_list = get_datalist(0)\n",
    "train_df = pd.DataFrame(train_list)\n",
    "train_list,train_df\n",
    "for i in range(1000):\n",
    "    print(train_list[i]['video'] == train_df.iloc[i]['video'])\n",
    "train_df\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "from sklearn.metrics import f1_score,precision_recall_curve,precision_score,recall_score,accuracy_score,balanced_accuracy_score\n",
    "y_true = [0, 0, 0, 1, 1, 1,   2]\n",
    "y_pred = [0, 0, 0, 1, 1, 1,   4]\n",
    "class AverageMethod(str, Enum):\n",
    "    MICRO = 'micro'\n",
    "    WEIGHTED = 'weighted'\n",
    "    MACRO = 'macro'\n",
    "def evaluate(y_true,y_pred,average:AverageMethod):\n",
    "    statistics = {}\n",
    "    statistics['f1_score'] = f1_score(y_true,y_pred,average=average.value)\n",
    "    statistics['precision'] = precision_score(y_true,y_pred,average=average.value)\n",
    "    statistics['recall'] = recall_score(y_true,y_pred,average=average.value)\n",
    "    statistics['accuracy'] = accuracy_score(y_true,y_pred)\n",
    "    return statistics\n",
    "evaluate(y_true,y_pred,AverageMethod.MACRO),balanced_accuracy_score(y_true,y_pred)\n",
    "\n",
    "\n",
    "# train_list,test_list = get_datalist(0)\n",
    "# train_loader ,test_loader = get_train_test_dataloader(16,0,train_list,test_list)\n",
    "\n",
    "# for train in train_loader:\n",
    "#     print(train)\n",
    "\n",
    "\n",
    "# def train_total():\n",
    "#     for task_id in range(5):\n",
    "#         train_list,test_list,cl_class_label,ul_class_label = clul.train_with_forget_without_forget_bank(task_id)\n",
    "#         if task_id == 0:\n",
    "#             clul.equal_class_sampling(train_list)\n",
    "#         else:\n",
    "#             clul.single_mutual_info_sampling(train_list,cl_class_label,ul_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6d381-9ff9-429d-83ee-197ff6f3cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "a = [1,2,3,4,5]\n",
    "for i in tqdm(a):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e9cbc-c3f4-4b0d-97c0-ccc2b90f32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button\n",
    "\n",
    "button = Button(description=\"Click me!\")\n",
    "button\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b6505-c203-426f-af70-25588633415d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7881c-d3c1-4582-a1de-c0bb8d5dd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning and Forget Together\n",
    "# Function All_Learn_Forget_No_memory_No_forget\n",
    "'cl_weighted_accuracy': 0.7549258960490488, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.841726618705036, 'ul_accuracy': 0.0\n",
    "\n",
    "# Learning All then forget \n",
    "# Function All_Learn_then_Forget()\n",
    "'cl_weighted_accuracy': 0.7121724674783099, 'ul_weighted_accuracy': nan, 'cl_accuracy': 0.8251804330392943, 'ul_accuracy': nan\n",
    "\n",
    "#Forget 1 class()\n",
    "statistics {'cl_weighted_accuracy': 0.40478523521049253, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.5871227364185111, 'ul_accuracy': 0.0}\n",
    "\n",
    "#Forget 12 class()\n",
    "'cl_weighted_accuracy': 0.0682041140002008,'ul_weighted_accuracy': 0.0,'cl_accuracy': 0.14148681055155876,'ul_accuracy': 0.0"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "CLUL",
   "language": "python",
   "name": "clul"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
