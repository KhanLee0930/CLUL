{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf742fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If U are using SageMaker Prepare for the dataset\n",
    "!pip install awscli\n",
    "!aws s3 cp s3://handata/ref_youtube_audio/ ref_youtube_audio/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -U openai-whisper\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e7a758-d85d-444c-aede-9f31a6fe37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, WhisperForAudioClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from categories import ytvos_category_dict\n",
    "import numpy as np\n",
    "from util import read_aws_json,read_aws_wav,read_local_json,read_local_wav\n",
    "import logging\n",
    "from torch import optim\n",
    "from losses import get_loss_func\n",
    "from utils.evaluate import Evaluator\n",
    "from util import infoNCE_loss\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from enum import Enum\n",
    "from sklearn.metrics import f1_score,precision_recall_curve,precision_score,recall_score,accuracy_score,balanced_accuracy_score\n",
    "from collections import Counter\n",
    "from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "import torch.nn.functional as F\n",
    "SageMaker = False\n",
    "Local = True\n",
    "ROOT = 'C:/Users/Administrator/Desktop/CLUL-main/data/'\n",
    "SAVEDIR = 'C:/Users/Administrator/Desktop/CLUL-main/run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a734c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Audio_Encoder(nn.Module):\n",
    "    def __init__(self, feature_extractor, model, num_class=66,dropout_prob=0.2,pool_num = 100,bias = True):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.encoder = model.encoder\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "          param.requires_grad = False\n",
    "        self.projector = nn.Linear(in_features=768, out_features=256, bias=True)\n",
    "        self.classifier = nn.Linear(256, num_class)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(pool_num,1), stride=(pool_num,1))\n",
    "        # self.norm_layer = nn.LayerNorm(256, eps=1e-5, bias=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(2048, affine=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(1500//pool_num * 256, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 256)\n",
    "        self.fc3 = nn.Linear(256, num_class)\n",
    "\n",
    "    def forward(self, audios):\n",
    "        input_features = []\n",
    "        for audio in audios:\n",
    "\n",
    "            feature = self.feature_extractor(audio.cpu(),sampling_rate=16000,return_tensors=\"pt\").input_features\n",
    "            input_features.append(feature)\n",
    "\n",
    "        input_features = torch.cat(input_features, dim=0).to(self.device)\n",
    "        hidden_states = self.encoder(input_features)\n",
    "        # hidden_states = self.projector(hidden_states)\n",
    "        # pooled_output = hidden_states.mean(dim=1)\n",
    "        # logits = self.classifier(pooled_output)\n",
    "\n",
    "        x = self.avg_pool(hidden_states)\n",
    "\n",
    "        x = self.projector(x)\n",
    "        # x = self.positionencoding(x)\n",
    "        feature = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(feature)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        output_dict = {\n",
    "            'clipwise_output': x,\n",
    "            'feature': feature,\n",
    "            'embedding': hidden_states}\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "class ytvos_Dataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame, sr=44100, num_class=66):\n",
    "        self.data_frame = data_frame\n",
    "        self.sr = sr\n",
    "        self.num_class = num_class\n",
    "        self.data_root = '/home/user/SED_Adaptation_Classifier-main/data/ref_youtube_audio/audio'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        audio_name = self.data_frame.iloc[index][\"video\"]\n",
    "        audio_id = self.data_frame.iloc[index][\"audio\"]\n",
    "        audio_path = 'ref_youtube_audio/audio' + '/' + audio_name + '/' + audio_id + '.wav'\n",
    "        name = audio_name + self.data_frame.iloc[index][\"exp\"]\n",
    "\n",
    "        \n",
    "        waveform = read_local_wav(ROOT + audio_path)\n",
    "#         waveform = whisper.load_audio(audio_path,sr = 16000)\n",
    "\n",
    "        tag = self.data_frame.iloc[index][\"category\"]\n",
    "        target = ytvos_category_dict[self.data_frame.iloc[index][\"category\"]]\n",
    "        target = np.eye(self.num_class)[target]\n",
    "        data_dict = {'audio_name': name, 'waveform': waveform, 'target': target, 'tag': tag}\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "def get_datalist(cur_iter):\n",
    "        task_id = cur_iter\n",
    "        task_train_metas = []\n",
    "        task_test_metas = []\n",
    "\n",
    "       \n",
    "        metas = read_local_json(ROOT + 'task_split_1/metas.json')['metas']\n",
    "        tasks = read_local_json(ROOT + 'task_split_1/task{}.json'.format(task_id))[str(task_id)]\n",
    "\n",
    "        for category,task_metas_dict in tasks.items():\n",
    "            train_ids = task_metas_dict['train']\n",
    "            test_ids = task_metas_dict['test']\n",
    "            for train_id in train_ids:\n",
    "                task_train_metas.append(metas[train_id])\n",
    "            for test_id in test_ids:\n",
    "                task_test_metas.append(metas[test_id])\n",
    "\n",
    "        return task_train_metas,task_test_metas\n",
    "    \n",
    "def default_collate_fn(batch):\n",
    "    audio_name = [data['audio_name'] for data in batch]\n",
    "    waveform = [torch.from_numpy(data['waveform']) for data in batch]\n",
    "    target = [data['target'] for data in batch]\n",
    "\n",
    "    # waveform = torch.FloatTensor(waveform)\n",
    "    # waveform = pad_sequence(waveform, batch_first=True, padding_value=0)\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    return {'audio_name': audio_name, 'waveform': waveform, 'target': target}\n",
    "\n",
    "def get_dataloader(data_frame, dataset,split, batch_size, num_workers=0):\n",
    "    assert dataset == \"ref_youtube_audio\"\n",
    "    dataset = ytvos_Dataset(data_frame=data_frame)\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                      shuffle=(split == 'train'), drop_last=False,\n",
    "                      num_workers=num_workers, collate_fn=default_collate_fn)\n",
    "\n",
    "def get_train_test_dataloader(batch_size, n_worker, train_list, test_list):\n",
    "    train_loader = get_dataloader(pd.DataFrame(train_list), 'ref_youtube_audio','train', batch_size=batch_size, \n",
    "                                  num_workers=n_worker)\n",
    "    test_loader = get_dataloader(pd.DataFrame(test_list), 'ref_youtube_audio','test', batch_size=batch_size, \n",
    "                                 num_workers=n_worker)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3d6cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLUL:\n",
    "    def __init__(self,batch_size = 16,lr = 1e-3,memory_size = 500,\n",
    "                 forget_size = 100,epoch=3,loss ='focal_loss',\n",
    "                 total_class_num = 65,mode = 'CLUL _no_foget_bank',\n",
    "                 patience = 10,n_worker = 0,\n",
    "                 **kwargs):\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "        whisper_model = whisper.load_model(\"small\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = Audio_Encoder(feature_extractor, whisper_model).to(self.device)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.logger = logging.getLogger()\n",
    "        self.forget_list = []\n",
    "        self.memory_list = []\n",
    "        self.memory_size = memory_size\n",
    "        self.forget_size = forget_size\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas=(0.9, 0.999))\n",
    "        self.criterion = get_loss_func(loss)\n",
    "        self.num_pretrain_class = 0\n",
    "        self.evaluator = Evaluator(self.model, self.num_pretrain_class, self.device)\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.total_class_num = total_class_num\n",
    "        self.forget_label = total_class_num\n",
    "        self.n_worker = n_worker\n",
    "        self.cltask = {\n",
    "            'task0':[15, 17, 60, 50, 32, 24, 63, 36, 31, 40, 52, 4, 25],\n",
    "            \"task1\":[48, 54, 35, 62, 13, 42, 37, 49, 51, 45, 44, 14, 5],\n",
    "            \"task2\":[46, 18, 57, 28, 11, 30, 61, 27, 22, 2, 29, 0, 19],\n",
    "            \"task3\":[3, 59, 10, 12, 8, 1, 26, 23, 34, 58, 64, 56, 41],\n",
    "            \"task4\":[47, 20, 53, 39, 9, 21, 16, 38, 33, 43, 6, 7, 55]\n",
    "        }\n",
    "        self.ultask = {\n",
    "            \"ul_task0\":[],\n",
    "            \"ul_task1\":[15,17,60],\n",
    "            \"ul_task2\": [48, 54, 35],\n",
    "            \"ul_task3\":[46, 18, 57],\n",
    "            \"ul_task4\" : [3, 59, 10],\n",
    "            \"ul_task5\" : [47, 20, 53]\n",
    "        }\n",
    "           \n",
    "    def evaluate(self,model_path,cur_iter):\n",
    "        self.change_model(model_path)\n",
    "        train_list,test_list = self.get_train_test_datalist(cur_iter)\n",
    "        _, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "        \n",
    "        cl_class_label,ul_class_label = self.get_cl_ul_class_label(cur_iter)\n",
    "        # statistics = self.calculate_metrics(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "        # print(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "        # return statistics\n",
    "        return y_true,y_pred,cl_class_label,ul_class_label\n",
    "\n",
    "    def get_train_test_datalist(self,cur_iter):\n",
    "        train_list,test_list = get_datalist(cur_iter)\n",
    "        for i in range(cur_iter):\n",
    "            _,test_list_ = get_datalist(i)\n",
    "            test_list += test_list_\n",
    "\n",
    "        return train_list,test_list\n",
    "        \n",
    "    def train(self,cur_iter):\n",
    "        streamed_list,test_list = get_datalist(cur_iter)\n",
    "        train_list = streamed_list + self.memory_list\n",
    "        random.shuffle(train_list)\n",
    "        train_loader, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "\n",
    "        self.logger.info(f\"Streamed samples: {len(streamed_list)}\")\n",
    "        self.logger.info(f\"In-memory samples: {len(self.memory_list)}\")\n",
    "        self.logger.info(f\"Train samples: {len(train_list)}\")\n",
    "        self.logger.info(f\"Test samples: {len(test_list)}\")\n",
    "        # logger.info(f\"Model: {self.model}\")\n",
    "        self.logger.info(f\"Optimizer: {self.optimizer}\")\n",
    "        acc_list = []\n",
    "        best = {'acc': 0, 'epoch': 0,'f1_score':0}\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            self.logger.info(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "            weighted_accuracy = balanced_accuracy_score(y_true,y_pred)\n",
    "            accuracy = accuracy_score(y_true,y_pred)\n",
    "            # ave_f1_score = np.mean(test_statistics['f1_score'])\n",
    "            # ave_acc = np.mean(test_statistics['accuracy'])\n",
    "            # acc_list.append(ave_acc)\n",
    "            # self.logger.info(f\"Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}\")\n",
    "            # self.logger.info(f'Current Accuracy: {ave_acc} in epoch {epoch}.|Current f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "            # print(f\"Task {cur_iter} | Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}|Evaluation precision {test_statistics['precision']}\")\n",
    "            \n",
    "\n",
    "            if weighted_accuracy > best['weighted_accuracy']:\n",
    "                best['weighted_accuracy'] = weighted_accuracy\n",
    "                best['accuracy'] = accuracy\n",
    "                best['epoch'] = epoch\n",
    "                self.logger.info(f'Best Accuracy: {accuracy} in epoch {epoch}.|Best weighted_accuracy: {weighted_accuracy} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Accuracy: {best['accuracy']}|Best weighted_accuracy: {best['weighted_accuracy']}\")\n",
    "        return \n",
    "    \n",
    "    def change_model(self, path):\n",
    "        checkpoint_dict = torch.load(path)\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if name in checkpoint_dict:\n",
    "                    param.data.copy_(checkpoint_dict[name])\n",
    "                \n",
    "    def equal_class_sampling(self, samples, num_class):\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cur_class_list = []\n",
    "        for i in range(num_class//13):\n",
    "            cur_class_list += class_list[i]\n",
    "        mem_per_cls = self.memory_size // num_class\n",
    "        sample_df = pd.DataFrame(samples)\n",
    "\n",
    "        # Warning: assuming the classes were ordered following task number.\n",
    "        ret = []\n",
    "        for y in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == y]\n",
    "            ret += cls_df.sample(n=min(mem_per_cls, len(cls_df))).to_dict(\n",
    "                orient=\"records\"\n",
    "            )\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            self.logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            self.logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_data(self, infer_loader, augment):\n",
    "        Z, Z_, predict_list = [], [], []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for id, data in enumerate(tqdm(infer_loader)):\n",
    "                wavs = data['waveform']\n",
    "                aug_wavs = []\n",
    "                for wav in wavs:\n",
    "                    aug_wav = augment(wav.unsqueeze(0).unsqueeze(0), sample_rate=1600)\n",
    "                    aug_wavs.append(torch.as_tensor(aug_wav.squeeze(0).squeeze(0), dtype=torch.float32))\n",
    "\n",
    "                output_dict = self.model(data['waveform'])\n",
    "                aug_output_dict = self.model(aug_wavs)\n",
    "\n",
    "                Z.extend(output_dict['feature'].cpu())\n",
    "                Z_.extend(aug_output_dict['feature'].cpu())\n",
    "\n",
    "                clipwise_output = output_dict['clipwise_output']\n",
    "                pres = np.argmax(clipwise_output.detach().cpu(), axis=1)\n",
    "                \n",
    "\n",
    "                for pre in pres: predict_list.append(pre.item())\n",
    "\n",
    "            class_label_dic = self.save_indexes(predict_list)\n",
    "        return Z, Z_, class_label_dic, predict_list\n",
    "    \n",
    "    def save_indexes(self,arr):\n",
    "        index_dict = {}\n",
    "        for idx, num in enumerate(arr):\n",
    "            if num in index_dict:\n",
    "                index_dict[num].append(idx)\n",
    "            else:\n",
    "                  index_dict[num] = [idx]\n",
    "        return index_dict\n",
    "\n",
    "    def forget_label_set(self,y_true,ul_class_label):\n",
    "        index_row = torch.argmax(y_true,dim=1)\n",
    "        for r ,c in enumerate(index_row):\n",
    "            if int(c) in ul_class_label:\n",
    "                with torch.no_grad():\n",
    "                    y_true[r][c] = torch.tensor(0.0, dtype=torch.float32)\n",
    "                    y_true[r][-1] = torch.tensor(1.0, dtype=torch.float32)\n",
    "        return y_true\n",
    "    \n",
    "    def class_infoNCE(self, Z, Z_, class_label_dic, predict_list, temperature):\n",
    "        ## You can change the method to calculate NCEs\n",
    "        NCEs = []\n",
    "        # print('This is cclass_label_dic',class_label_dic)\n",
    "        for id in range(len(predict_list)):\n",
    "            label = predict_list[id]\n",
    "            same_label_list = class_label_dic[label]\n",
    "            class_z = [Z[i] for i in same_label_list if i != id]\n",
    "            class_z_ = [Z_[i] for i in same_label_list]\n",
    "\n",
    "            positive_pair = class_z + class_z_\n",
    "\n",
    "            positive_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(positive_pair)) / 2 + 0.5\n",
    "            # print('This is postitive pair info',Z[id].unsqueeze(0).shape,torch.stack(positive_pair).shape,positive_similarities.shape)\n",
    "            positive_value = torch.exp(positive_similarities / temperature).sum() / len(positive_pair)\n",
    "            # print(positive_similarities,positive_value)\n",
    "            neg_labels = [i for i in list(class_label_dic.keys()) if i != label]\n",
    "\n",
    "            negative_values = 0\n",
    "            for neg_label in neg_labels:\n",
    "                neg_label_list = class_label_dic[neg_label]\n",
    "                neg_z = [Z[i] for i in neg_label_list]\n",
    "                neg_z_ = [Z_[i] for i in neg_label_list]\n",
    "                negative_pair = neg_z + neg_z_\n",
    "                negative_similarities = F.cosine_similarity(Z[id].unsqueeze(0), torch.stack(negative_pair)) / 2 + 0.5\n",
    "                # print('This is negative pair info',Z[id].unsqueeze(0).shape,torch.stack(negative_pair).shape,negative_similarities.shape,len(negative_pair))\n",
    "                negative_value = torch.exp(negative_similarities / temperature).sum() / len(negative_pair)\n",
    "                # print(negative_similarities,negative_value)\n",
    "                negative_values += negative_value\n",
    "\n",
    "            NCE = -torch.log(positive_value / (positive_value + negative_values))\n",
    "            # print('positive_value',positive_value,'negative values', negative_values,'this is single nce',NCE)\n",
    "            NCEs.append(NCE)\n",
    "        print(torch.stack(NCEs).shape)\n",
    "        return torch.stack(NCEs)\n",
    "    \n",
    "    def single_mutual_info_sampling(self,cur_iter, train_list, cl_class_label, ul_class_label):\n",
    "        ret_mem = []\n",
    "        val_class_label = list(set(cl_class_label) - set(ul_class_label))\n",
    "        train_df = pd.DataFrame(train_list)\n",
    "        train_df['category_id'] = train_df['category'].map(ytvos_category_dict)\n",
    "\n",
    "        train_df = train_df[train_df['category_id']. isin( val_class_label)]\n",
    "        assert len(Counter(train_df['category'])) == len(val_class_label)\n",
    "\n",
    "        inf_loader = get_dataloader(train_df, 'ref_youtube_audio', 'test', self.batch_size, self.n_worker)\n",
    "        temperature = 0.05\n",
    "\n",
    "\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        #Calculate current infoNCE\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(inf_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "\n",
    "        #Calculate previous infoNCE\n",
    "\n",
    "        self.change_model(SAVEDIR + '{}/task{}best_epoch2.pt'.format(self.mode,cur_iter-1))\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(inf_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "        self.change_model(SAVEDIR + '{}/task{}best_epoch2.pt'.format(self.mode,cur_iter))\n",
    "\n",
    "        \n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        train_df['NCE'] = NCEs\n",
    "\n",
    "        mem_per_cls = self.memory_size // len(val_class_label)\n",
    "\n",
    "        for i in val_class_label:\n",
    "            cls_df = train_df[(train_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret_mem += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret_mem += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret_mem)\n",
    "        if num_rest_slots > 0:\n",
    "            self.logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret_mem += (\n",
    "                train_df[~train_df.exp.isin(pd.DataFrame(ret_mem).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret_mem).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            self.logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret_mem)['category'])\n",
    "        print('After Unpdate Statistics',class_count)\n",
    "        \n",
    "        return ret_mem\n",
    "      \n",
    "    def double_mutual_info_sampling(self, candidates, cur, num_class):\n",
    "        from audiomentations import Compose, Gain, AddGaussianNoise, PitchShift,TimeStretch,Shift\n",
    "        from collections import Counter\n",
    "        \n",
    "        ulclass_list =   [None,self.ultask[\"task1\"],self.ultask[\"task2\"],self.ultask[\"task3\"],self.ultask[\"task4\"]]\n",
    "        class_list = [self.cltask[\"task0\"], self.cltask[\"task1\"],self.cltask[\"task2\"],self.cltask[\"task3\"],self.cltask[\"task4\"]]\n",
    "        cl_class_list = []\n",
    "        ul_class_list = []\n",
    "        for i in range(num_class // 13):\n",
    "            cur_class_list |= set(class_list[i])\n",
    "            cur_class_list -= set(ulclass_list[i])\n",
    "        cur_class_list.add(self.total_class_num-1)\n",
    "        # Unlearning Part:class deleted will not be added into the memory bank\n",
    "\n",
    "        infer_df = pd.DataFrame(candidates)\n",
    "\n",
    "        class_count = Counter(infer_df['category'])\n",
    "        print('Before Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "        # mem_per_cls = self.memory_size // num_class  # kc: the number of the samples of each class\n",
    "\n",
    "        batch_size = 8\n",
    "        temperature = 0.05\n",
    "        ret = []\n",
    "        infer_loader = get_dataloader(infer_df, 'ref_youtube_audio', split='test', batch_size=batch_size, num_class=num_class,\n",
    "                                      num_workers=8)\n",
    "        augment = Compose([\n",
    "            # Gain(min_gain_in_db=-12.0, max_gain_in_db=12.0),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.001),\n",
    "            PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.5),\n",
    "            # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
    "            # TimeShift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            # TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "        ])\n",
    "\n",
    "        Z, Z_, class_label_dic, predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        cur_NCEs = self.class_infoNCE(Z, Z_, class_label_dic, predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur - 1)\n",
    "        self.change_model(path)\n",
    "\n",
    "        pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list = self.get_data(infer_loader, augment)\n",
    "        assert (len(Z) == len(Z_) == len(predict_list))\n",
    "\n",
    "        pre_NCEs = self.class_infoNCE(pre_Z, pre_Z_, pre_class_label_dic, pre_predict_list, temperature)\n",
    "\n",
    "        path = '/home/user/SED_Adaptation_Classifier-main/workspace/ref_youtube/MIO/iter{}epoch.pt'.format(cur)\n",
    "        self.change_model(path)\n",
    "\n",
    "        # print(len(Z),len(Z_),len(predict_list),len(candidates))\n",
    "\n",
    "        NCEs = pre_NCEs - cur_NCEs\n",
    "        for candidate,NCE in zip(candidates,NCEs):candidate['NCE'] = NCE\n",
    "\n",
    "        sample_df = pd.DataFrame(candidates)\n",
    "         # kc: the number of the samples of each class in memory bank\n",
    "        mem_per_cls = self.memory_size // len(cl_class_list)\n",
    "        \n",
    "        for_per_cls = self.forget_size// len(ul_class_list)\n",
    "        \n",
    "\n",
    "\n",
    "        for i in cur_class_list:\n",
    "            cls_df = sample_df[(sample_df[\"category\"].map(ytvos_category_dict)) == i]\n",
    "            if len(cls_df) <= mem_per_cls:\n",
    "                ret += cls_df.to_dict(orient=\"records\")\n",
    "            else:\n",
    "                jump_idx = len(cls_df) // mem_per_cls\n",
    "                uncertain_samples = cls_df.sort_values(by=\"NCE\")[::jump_idx]\n",
    "                ret += uncertain_samples[:mem_per_cls].to_dict(orient=\"records\")\n",
    "\n",
    "        num_rest_slots = self.memory_size - len(ret)\n",
    "        if num_rest_slots > 0:\n",
    "            logger.warning(\"Fill the unused slots by breaking the equilibrium.\")\n",
    "            ret += (\n",
    "                sample_df[~sample_df.exp.isin(pd.DataFrame(ret).exp)]\n",
    "                .sample(n=num_rest_slots)\n",
    "                .to_dict(orient=\"records\")\n",
    "            )\n",
    "\n",
    "        num_dups = pd.DataFrame(ret).exp.duplicated().sum()\n",
    "        if num_dups > 0:\n",
    "            logger.warning(f\"Duplicated samples in memory: {num_dups}\")\n",
    "\n",
    "\n",
    "        # top_indices = np.argpartition(NCEs.cpu().numpy(), -2000)[-2000:]\n",
    "        #\n",
    "        # for index in top_indices:\n",
    "        #     ret.append(candidates[index])\n",
    "\n",
    "        class_count = Counter(pd.DataFrame(ret)['category'])\n",
    "        print('After Unpdate Statistics')\n",
    "        for name, number in class_count.items():\n",
    "            print(name, number)\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def train_with_datalist(self,train_list,test_list):\n",
    "        \n",
    "        train_loader, test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        self.logger.info(f\"In-memory samples: {len(self.memory_list)}\")\n",
    "        self.logger.info(f\"Train samples: {len(train_list)}\")\n",
    "        self.logger.info(f\"Test samples: {len(test_list)}\")\n",
    "        # logger.info(f\"Model: {self.model}\")\n",
    "        self.logger.info(f\"Optimizer: {self.optimizer}\")\n",
    "        acc_list = []\n",
    "        best = {'acc': 0, 'epoch': 0,'f1_score':0}\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            self.logger.info(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            test_statistics = self.evaluator.evaluate(test_loader)\n",
    "            ave_f1_score = np.mean(test_statistics['f1_score'])\n",
    "            ave_acc = np.mean(test_statistics['accuracy'])\n",
    "            acc_list.append(ave_acc)\n",
    "            self.logger.info(f\"Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}\")\n",
    "            self.logger.info(f'Current Accuracy: {ave_acc} in epoch {epoch}.|Current f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "            print(f\"Task {cur_iter} | Epoch {epoch} | Evaluation Accuracy: {ave_acc}|Evaluation f1_score: {ave_f1_score}|Evaluation precision {test_statistics['precision']}\")\n",
    "            \n",
    "\n",
    "            if ave_f1_score > best['f1_score']:\n",
    "                best['acc'] = ave_acc\n",
    "                best['f1_score'] = ave_f1_score\n",
    "                best['epoch'] = epoch\n",
    "                self.logger.info(f'Best Accuracy: {ave_acc} in epoch {epoch}.|Best f1_score: {ave_f1_score} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Evaluation Accuracy: {best['acc']}|Evaluation f1_score: {best['f1_score']}\")\n",
    "        return \n",
    "    \n",
    "    def train_with_forget_without_forget_bank(self, cur_iter):\n",
    "        # For tets\n",
    "        \n",
    "        memory_bank = self.memory_list\n",
    "        test_list = []\n",
    "        for i in range(cur_iter + 1):\n",
    "            train_list_,test_data_list_ = get_datalist(i)\n",
    "            test_list += test_data_list_\n",
    "        \n",
    "        train_list,_ = get_datalist(cur_iter)\n",
    "        train_list += memory_bank\n",
    "\n",
    "        train_loader,test_loader = get_train_test_dataloader(self.batch_size, self.n_worker, train_list, test_list)\n",
    "        cl_class_label,ul_class_label = [],[]\n",
    "\n",
    "        best = {'cl_weighted_accuracy':0,'cl_accuracy':0,'ul_weighted_accuracy':0,'ul_accuracy':0,'epoch':0}\n",
    "        for i in range(cur_iter + 1):\n",
    "            cl_class_label += self.cltask[f'task{i}']\n",
    "            ul_class_label += self.ultask[f'ul_task{i}']\n",
    "        print('train loader length',len(train_loader),'test loader length',len(test_loader),'cl class label',cl_class_label,'ul class label',ul_class_label)\n",
    "        for epoch in range(self.epoch):\n",
    "            mean_loss = 0\n",
    "            for idx,batch_data_dict in enumerate(tqdm(train_loader)):\n",
    "                batch_data_dict['waveform'] = batch_data_dict['waveform']\n",
    "                # print(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = self.forget_label_set(batch_data_dict['target'],ul_class_label)\n",
    "                batch_data_dict['target'] = batch_data_dict['target'].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                self.model.train()\n",
    "\n",
    "                batch_output_dict = self.model(batch_data_dict['waveform'])\n",
    "                \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "                batch_target_dict = {'target': batch_data_dict['target']}\n",
    "                \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "                # Loss\n",
    "                \n",
    "                loss = self.criterion(batch_output_dict, batch_target_dict)\n",
    "                self.logger.info(f'Batch Training Initial Loss: {loss}')\n",
    "                if idx % 10 == 0:\n",
    "                    print(f'Epoch:{epoch},Batch {idx} Loss: {loss}')\n",
    "                # Backwards\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                mean_loss += loss\n",
    "            epoch_loss = mean_loss / len(train_loader)\n",
    "            \n",
    "            print(f'Epoch {epoch} | Training Loss: {epoch_loss}')\n",
    "            # Evaluate\n",
    "            y_true,y_pred = self.evaluator.evaluate(test_loader)\n",
    "\n",
    "            statistics = self.calculate_metrics(y_true,y_pred,cl_class_label,ul_class_label)\n",
    "\n",
    "            print(f\"Task {cur_iter} |  Epoch {epoch} | statistics {statistics}\")\n",
    "            if  statistics['cl_weighted_accuracy'] > best['cl_weighted_accuracy']:\n",
    "                best['cl_weighted_accuracy'] = statistics['cl_weighted_accuracy']\n",
    "                best['cl_accuracy'] = statistics['cl_accuracy']\n",
    "                best['epoch'] = epoch\n",
    "                # self.logger.info(f'Best Accuracy: {accuracy} in epoch {epoch}.|Best weighted_accuracy: {weighted_accuracy} in epoch {epoch}.')\n",
    "                selected_state_dict = {}\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'projector' in name or 'classifier' in name or 'fc' in name and ('encoder' not in name):\n",
    "                        selected_state_dict[name] = param\n",
    "                torch.save(selected_state_dict,SAVEDIR + '{}/task{}best_epoch{}.pt'.format(self.mode,cur_iter,epoch))\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}.')\n",
    "                if self.counter >= self.patience:\n",
    "                    break\n",
    "        print(f\"Task {cur_iter} | Best Epoch {best['epoch']} | Best Accuracy: {best['cl_accuracy']}|Best weighted_accuracy: {best['cl_weighted_accuracy']}\")\n",
    "        return train_list,test_list,cl_class_label,ul_class_label\n",
    "        \n",
    "    def calculate_metrics(self,y_true,y_pred,cl_class_label,ul_class_label):\n",
    "        statistics = {'cl_weighted_accuracy':0,'ul_weighted_accuracy':0,'cl_accuracy':0,'ul_accuracy':0}\n",
    "        cl_y_true,cl_y_pred = [],[]\n",
    "        ul_y_true,ul_y_pred = [],[]\n",
    "        for y_t,y_d in zip(y_true,y_pred):\n",
    "            if y_t in cl_class_label and y_t not in ul_class_label:\n",
    "                cl_y_true.append(y_t)\n",
    "                cl_y_pred.append(y_d)\n",
    "            else:\n",
    "                ul_y_true.append(y_t)\n",
    "                ul_y_pred.append(y_d)\n",
    "\n",
    "        cl_weighted_accuracy = balanced_accuracy_score(cl_y_true,cl_y_pred)\n",
    "        ul_weighted_accuracy = balanced_accuracy_score(ul_y_true,ul_y_pred)\n",
    "\n",
    "        cl_accuracy = accuracy_score(cl_y_true,cl_y_pred)\n",
    "        ul_accuracy = accuracy_score(ul_y_true,ul_y_pred)\n",
    "\n",
    "        statistics['ul_accuracy'] = ul_accuracy\n",
    "        statistics['cl_accuracy'] = cl_accuracy\n",
    "\n",
    "        statistics['cl_weighted_accuracy'] = cl_weighted_accuracy\n",
    "        statistics['ul_weighted_accuracy'] = ul_weighted_accuracy\n",
    "\n",
    "        return statistics\n",
    "\n",
    "    def get_cl_ul_class_label(self,cur_iter):\n",
    "        cl_class_label = []\n",
    "        ul_class_label = []\n",
    "        for i in range(cur_iter + 1):\n",
    "            cl_class_label += self.cltask[f'task{i}']\n",
    "            ul_class_label += self.ultask[f'ul_task{i}']\n",
    "        return cl_class_label,ul_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de3fca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader length 344 test loader length 87 cl class label [15, 17, 60, 50, 32, 24, 63, 36, 31, 40, 52, 4, 25, 48, 54, 35, 62, 13, 42, 37, 49, 51, 45, 44, 14, 5] ul class label [15, 17, 60]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4862882b9bd443b89ec498cbc60ed4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Batch 0 Loss: 149.96710205078125\n",
      "Epoch:0,Batch 10 Loss: 35.28391647338867\n",
      "Epoch:0,Batch 20 Loss: 53.58418273925781\n",
      "Epoch:0,Batch 30 Loss: 146.04888916015625\n",
      "Epoch:0,Batch 40 Loss: 80.38053894042969\n",
      "Epoch:0,Batch 50 Loss: 57.942134857177734\n",
      "Epoch:0,Batch 60 Loss: 21.2530574798584\n",
      "Epoch:0,Batch 70 Loss: 11.239953994750977\n",
      "Epoch:0,Batch 80 Loss: 10.870521545410156\n",
      "Epoch:0,Batch 90 Loss: 7.318578720092773\n",
      "Epoch:0,Batch 100 Loss: 11.205635070800781\n",
      "Epoch:0,Batch 110 Loss: 9.542596817016602\n",
      "Epoch:0,Batch 120 Loss: 6.019320487976074\n",
      "Epoch:0,Batch 130 Loss: 10.744497299194336\n",
      "Epoch:0,Batch 140 Loss: 23.411678314208984\n",
      "Epoch:0,Batch 150 Loss: 8.346343040466309\n",
      "Epoch:0,Batch 160 Loss: 7.815056324005127\n",
      "Epoch:0,Batch 170 Loss: 4.884488105773926\n",
      "Epoch:0,Batch 180 Loss: 5.39385986328125\n",
      "Epoch:0,Batch 190 Loss: 4.6748223304748535\n",
      "Epoch:0,Batch 200 Loss: 3.640554189682007\n",
      "Epoch:0,Batch 210 Loss: 5.444130897521973\n",
      "Epoch:0,Batch 220 Loss: 3.850447654724121\n",
      "Epoch:0,Batch 230 Loss: 4.837438583374023\n",
      "Epoch:0,Batch 240 Loss: 4.093402862548828\n",
      "Epoch:0,Batch 250 Loss: 5.376343250274658\n",
      "Epoch:0,Batch 260 Loss: 4.026775360107422\n",
      "Epoch:0,Batch 270 Loss: 5.063690662384033\n",
      "Epoch:0,Batch 280 Loss: 3.00362229347229\n",
      "Epoch:0,Batch 290 Loss: 4.3080596923828125\n",
      "Epoch:0,Batch 300 Loss: 3.7219038009643555\n",
      "Epoch:0,Batch 310 Loss: 2.101424217224121\n",
      "Epoch:0,Batch 320 Loss: 4.794352054595947\n",
      "Epoch:0,Batch 330 Loss: 2.8367722034454346\n",
      "Epoch:0,Batch 340 Loss: 3.209925651550293\n",
      "Epoch 0 | Training Loss: 18.433574490075888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 87/87 [03:03<00:00,  2.11s/it]\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned target_acc and clipwise_output_acc\n",
      "Task 1 |  Epoch 0 | statistics {'cl_weighted_accuracy': 0.24401878573442193, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.6309148264984227, 'ul_accuracy': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a579dc96c24b4c8db8f151b71987fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,Batch 0 Loss: 2.8204727172851562\n",
      "Epoch:1,Batch 10 Loss: 4.041495323181152\n",
      "Epoch:1,Batch 20 Loss: 3.8323445320129395\n",
      "Epoch:1,Batch 30 Loss: 2.6267309188842773\n",
      "Epoch:1,Batch 40 Loss: 2.112574338912964\n",
      "Epoch:1,Batch 50 Loss: 1.8579294681549072\n",
      "Epoch:1,Batch 60 Loss: 2.9058480262756348\n",
      "Epoch:1,Batch 70 Loss: 2.039938449859619\n",
      "Epoch:1,Batch 80 Loss: 2.8253655433654785\n",
      "Epoch:1,Batch 90 Loss: 2.2961959838867188\n",
      "Epoch:1,Batch 100 Loss: 3.1383769512176514\n",
      "Epoch:1,Batch 110 Loss: 2.5237696170806885\n",
      "Epoch:1,Batch 120 Loss: 3.9418983459472656\n",
      "Epoch:1,Batch 130 Loss: 3.3030753135681152\n",
      "Epoch:1,Batch 140 Loss: 2.764458179473877\n",
      "Epoch:1,Batch 150 Loss: 2.0069632530212402\n",
      "Epoch:1,Batch 160 Loss: 2.1430816650390625\n",
      "Epoch:1,Batch 170 Loss: 2.762963056564331\n",
      "Epoch:1,Batch 180 Loss: 2.6114578247070312\n",
      "Epoch:1,Batch 190 Loss: 2.330460786819458\n",
      "Epoch:1,Batch 200 Loss: 2.276695489883423\n",
      "Epoch:1,Batch 210 Loss: 2.732628345489502\n",
      "Epoch:1,Batch 220 Loss: 1.6079418659210205\n",
      "Epoch:1,Batch 230 Loss: 1.540088415145874\n",
      "Epoch:1,Batch 240 Loss: 2.205007553100586\n",
      "Epoch:1,Batch 250 Loss: 1.1144298315048218\n",
      "Epoch:1,Batch 260 Loss: 2.7596335411071777\n",
      "Epoch:1,Batch 270 Loss: 3.415522336959839\n",
      "Epoch:1,Batch 280 Loss: 2.965318202972412\n",
      "Epoch:1,Batch 290 Loss: 2.0998787879943848\n",
      "Epoch:1,Batch 300 Loss: 4.956607818603516\n",
      "Epoch:1,Batch 310 Loss: 2.1653308868408203\n",
      "Epoch:1,Batch 320 Loss: 1.9952919483184814\n",
      "Epoch:1,Batch 330 Loss: 1.3736363649368286\n",
      "Epoch:1,Batch 340 Loss: 2.813497543334961\n",
      "Epoch 1 | Training Loss: 2.6890709242501925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 87/87 [03:03<00:00,  2.10s/it]\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned target_acc and clipwise_output_acc\n",
      "Task 1 |  Epoch 1 | statistics {'cl_weighted_accuracy': 0.5796354382174266, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.8272870662460567, 'ul_accuracy': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0adf4e8bc045c1a6170524258099f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2,Batch 0 Loss: 2.2180776596069336\n",
      "Epoch:2,Batch 10 Loss: 1.149743676185608\n",
      "Epoch:2,Batch 20 Loss: 2.6657328605651855\n",
      "Epoch:2,Batch 30 Loss: 1.7959067821502686\n",
      "Epoch:2,Batch 40 Loss: 2.532240867614746\n",
      "Epoch:2,Batch 50 Loss: 2.1255688667297363\n",
      "Epoch:2,Batch 60 Loss: 1.7622326612472534\n",
      "Epoch:2,Batch 70 Loss: 1.4204719066619873\n",
      "Epoch:2,Batch 80 Loss: 2.06888747215271\n",
      "Epoch:2,Batch 90 Loss: 1.9918067455291748\n",
      "Epoch:2,Batch 100 Loss: 1.0454607009887695\n",
      "Epoch:2,Batch 110 Loss: 2.023538589477539\n",
      "Epoch:2,Batch 120 Loss: 2.5973567962646484\n",
      "Epoch:2,Batch 130 Loss: 1.3309922218322754\n",
      "Epoch:2,Batch 140 Loss: 3.464616537094116\n",
      "Epoch:2,Batch 150 Loss: 1.3422188758850098\n",
      "Epoch:2,Batch 160 Loss: 0.972754955291748\n",
      "Epoch:2,Batch 170 Loss: 2.200571060180664\n",
      "Epoch:2,Batch 180 Loss: 3.4551117420196533\n",
      "Epoch:2,Batch 190 Loss: 1.317673921585083\n",
      "Epoch:2,Batch 200 Loss: 1.2053799629211426\n",
      "Epoch:2,Batch 210 Loss: 3.5620365142822266\n",
      "Epoch:2,Batch 220 Loss: 0.7810924053192139\n",
      "Epoch:2,Batch 230 Loss: 0.7360848188400269\n",
      "Epoch:2,Batch 240 Loss: 2.1788434982299805\n",
      "Epoch:2,Batch 250 Loss: 2.5764894485473633\n",
      "Epoch:2,Batch 260 Loss: 2.2580275535583496\n",
      "Epoch:2,Batch 270 Loss: 1.846292495727539\n",
      "Epoch:2,Batch 280 Loss: 1.4071927070617676\n",
      "Epoch:2,Batch 290 Loss: 1.7463281154632568\n",
      "Epoch:2,Batch 300 Loss: 2.48486328125\n",
      "Epoch:2,Batch 310 Loss: 2.233628034591675\n",
      "Epoch:2,Batch 320 Loss: 2.7935843467712402\n",
      "Epoch:2,Batch 330 Loss: 3.349102258682251\n",
      "Epoch:2,Batch 340 Loss: 2.0765762329101562\n",
      "Epoch 2 | Training Loss: 1.9061236431778863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation starting ...: 100%|██████████| 87/87 [03:02<00:00,  2.09s/it]\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned target_acc and clipwise_output_acc\n",
      "Task 1 |  Epoch 2 | statistics {'cl_weighted_accuracy': 0.7339985703974596, 'ul_weighted_accuracy': 0.0, 'cl_accuracy': 0.8769716088328076, 'ul_accuracy': 0.0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'weighted_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m clul \u001b[38;5;241m=\u001b[39m CLUL()\n\u001b[0;32m      2\u001b[0m clul\u001b[38;5;241m.\u001b[39mmemory_list,_\u001b[38;5;241m=\u001b[39m train_list1,test_list1 \u001b[38;5;241m=\u001b[39m clul\u001b[38;5;241m.\u001b[39mget_train_test_datalist(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_with_forget_without_forget_bank\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 581\u001b[0m, in \u001b[0;36mCLUL.train_with_forget_without_forget_bank\u001b[1;34m(self, cur_iter)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience:\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Best Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Best Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|Best weighted_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_list,test_list,cl_class_label,ul_class_label\n",
      "\u001b[1;31mKeyError\u001b[0m: 'weighted_accuracy'"
     ]
    }
   ],
   "source": [
    "clul = CLUL()\n",
    "clul.memory_list,_= train_list1,test_list1 = clul.get_train_test_datalist(0)\n",
    "clul.train_with_forget_without_forget_bank(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f418b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a130ccbfb3c4a3487c047b99a1965d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\audiomentations\\augmentations\\pitch_shift.py:50: UserWarning: Warning: You are probably using an old version of librosa. Upgrade librosa to 0.9.0 or later for better performance when applying PitchShift to stereo audio.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m ul_class_label \u001b[38;5;241m=\u001b[39m ul_class_label1 \u001b[38;5;241m+\u001b[39m ul_class_label2\n\u001b[0;32m     12\u001b[0m clul\u001b[38;5;241m.\u001b[39mchange_model(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdministrator\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCLUL-main\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCLUL _no_foget_bank\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtask1best_epoch2.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[43mclul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_mutual_info_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcl_class_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43mul_class_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 289\u001b[0m, in \u001b[0;36mCLUL.single_mutual_info_sampling\u001b[1;34m(self, cur_iter, train_list, cl_class_label, ul_class_label)\u001b[0m\n\u001b[0;32m    287\u001b[0m Z, Z_, class_label_dic, predict_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(train_loader, augment)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(Z) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(Z_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(predict_list))\n\u001b[1;32m--> 289\u001b[0m cur_NCEs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_infoNCE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_label_dic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m#Calculate previous infoNCE\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchange_model(SAVEDIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/task\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mbest_epoch2.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,cur_iter\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[34], line 239\u001b[0m, in \u001b[0;36mCLUL.class_infoNCE\u001b[1;34m(self, Z, Z_, class_label_dic, predict_list, temperature)\u001b[0m\n\u001b[0;32m    235\u001b[0m class_z_ \u001b[38;5;241m=\u001b[39m [Z_[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m same_label_list]\n\u001b[0;32m    237\u001b[0m positive_pair \u001b[38;5;241m=\u001b[39m class_z \u001b[38;5;241m+\u001b[39m class_z_\n\u001b[1;32m--> 239\u001b[0m positive_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mcosine_similarity(Z[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mstack(positive_pair)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# print('This is postitive pair info',Z[id].unsqueeze(0).shape,torch.stack(positive_pair).shape,positive_similarities.shape)\u001b[39;00m\n\u001b[0;32m    241\u001b[0m positive_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(positive_similarities \u001b[38;5;241m/\u001b[39m temperature)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(positive_pair)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "train_list1,test_list1 = clul.get_train_test_datalist(0)\n",
    "cl_class_label1,ul_class_label1 = clul.get_cl_ul_class_label(0)\n",
    "\n",
    "train_list2,test_list2 = clul.get_train_test_datalist(1)\n",
    "cl_class_label2,ul_class_label2 = clul.get_cl_ul_class_label(1)\n",
    "\n",
    "train_list = train_list1 + train_list2\n",
    "cl_class_label = cl_class_label1 + cl_class_label2\n",
    "ul_class_label = ul_class_label1 + ul_class_label2\n",
    "\n",
    "\n",
    "clul.change_model(r'C:\\Users\\Administrator\\Desktop\\CLUL-main\\run\\CLUL _no_foget_bank\\task1best_epoch2.pt')\n",
    "memory = clul.single_mutual_info_sampling(1,train_list,cl_class_label,ul_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3d49df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\envs\\CLUL38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'f1_score': 0.5,\n",
       "  'precision': 0.5,\n",
       "  'recall': 0.5,\n",
       "  'accuracy': 0.8571428571428571},\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_label_dic\n",
    "train_list,test_list = get_datalist(0)\n",
    "train_df = pd.DataFrame(train_list)\n",
    "train_list,train_df\n",
    "for i in range(1000):\n",
    "    print(train_list[i]['video'] == train_df.iloc[i]['video'])\n",
    "train_df\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "from sklearn.metrics import f1_score,precision_recall_curve,precision_score,recall_score,accuracy_score,balanced_accuracy_score\n",
    "y_true = [0, 0, 0, 1, 1, 1,   2]\n",
    "y_pred = [0, 0, 0, 1, 1, 1,   4]\n",
    "class AverageMethod(str, Enum):\n",
    "    MICRO = 'micro'\n",
    "    WEIGHTED = 'weighted'\n",
    "    MACRO = 'macro'\n",
    "def evaluate(y_true,y_pred,average:AverageMethod):\n",
    "    statistics = {}\n",
    "    statistics['f1_score'] = f1_score(y_true,y_pred,average=average.value)\n",
    "    statistics['precision'] = precision_score(y_true,y_pred,average=average.value)\n",
    "    statistics['recall'] = recall_score(y_true,y_pred,average=average.value)\n",
    "    statistics['accuracy'] = accuracy_score(y_true,y_pred)\n",
    "    return statistics\n",
    "evaluate(y_true,y_pred,AverageMethod.MACRO),balanced_accuracy_score(y_true,y_pred)\n",
    "\n",
    "\n",
    "# train_list,test_list = get_datalist(0)\n",
    "# train_loader ,test_loader = get_train_test_dataloader(16,0,train_list,test_list)\n",
    "\n",
    "# for train in train_loader:\n",
    "#     print(train)\n",
    "\n",
    "\n",
    "# def train_total():\n",
    "#     for task_id in range(5):\n",
    "#         train_list,test_list,cl_class_label,ul_class_label = clul.train_with_forget_without_forget_bank(task_id)\n",
    "#         if task_id == 0:\n",
    "#             clul.equal_class_sampling(train_list)\n",
    "#         else:\n",
    "#             clul.single_mutual_info_sampling(train_list,cl_class_label,ul_class_label)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "CLUL38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
